

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon.png">
  <link rel="icon" href="/images/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="smalnote">
  <meta name="keywords" content="">
  
    <meta name="description" content="Kafka 服务端 BrokerServer 的请求处理模型为主从 Reactor 多线程模型，本文以 v3.3 具体分析一下 kafka-core 的 Scala 源码如何实现这个模型，以应对海量的并发请求。  BrokerServer#startup()Kafka Broker 启动入口在 class BrokerServer, 会根据 KafkaConfig   创建 SocketServe">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka Reator 模型源代码分析">
<meta property="og:url" content="http://smalnote.github.io/2022/09/25/Kafka%20Reator%20%E6%A8%A1%E5%9E%8B%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="Smalnote">
<meta property="og:description" content="Kafka 服务端 BrokerServer 的请求处理模型为主从 Reactor 多线程模型，本文以 v3.3 具体分析一下 kafka-core 的 Scala 源码如何实现这个模型，以应对海量的并发请求。  BrokerServer#startup()Kafka Broker 启动入口在 class BrokerServer, 会根据 KafkaConfig   创建 SocketServe">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://smalnote.github.io/images/main_sub_reactor_model.png">
<meta property="og:image" content="http://smalnote.github.io/images/kafka_reactor_flow.drawio.svg">
<meta property="article:published_time" content="2022-09-25T15:00:00.000Z">
<meta property="article:modified_time" content="2024-12-16T08:12:58.756Z">
<meta property="article:author" content="smalnote">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://smalnote.github.io/images/main_sub_reactor_model.png">
  
  
  
  <title>Kafka Reator 模型源代码分析 - Smalnote</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"smalnote.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Smalnote</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/qq_lion.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Kafka Reator 模型源代码分析"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-09-25 23:00" pubdate>
          2022年9月25日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          101k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          843 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Kafka Reator 模型源代码分析</h1>
            
            
              <div class="markdown-body">
                
                <p>Kafka 服务端 BrokerServer 的请求处理模型为主从 Reactor 多线程模型，本文以 <a target="_blank" rel="noopener" href="https://github.com/apache/kafka/tree/3.3">v3.3</a> 具体分析一下 kafka-core 的 Scala 源码如何实现这个模型，以应对海量的并发请求。<br><img src="/../images/main_sub_reactor_model.png" srcset="/img/loading.gif" lazyload alt="Single MainReactor &amp; Multiple SubReactor Model"></p>
<p><img src="/../images/kafka_reactor_flow.drawio.svg" srcset="/img/loading.gif" lazyload alt="简化的类图及调用链"></p>
<h3 id="BrokerServer-startup"><a href="#BrokerServer-startup" class="headerlink" title="BrokerServer#startup()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/server/BrokerServer.scala?L180">BrokerServer#startup()</a></h3><p>Kafka Broker 启动入口在 class BrokerServer, 会根据 KafkaConfig </p>
<ol>
<li>创建 SocketServer, 调用其 enableRequestProcessing 监听配置的端口处理请求，请求分为两类：data plane request, control plane request</li>
<li>创建 dataPlaneRequestHandlerPool 独立的线程池处理请求</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * A Kafka broker that runs in KRaft (Kafka Raft) mode.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BrokerServer</span>(<span class="hljs-params">...</span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">KafkaBroker</span> </span>&#123;<br><br>	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">replicaManager</span></span>: <span class="hljs-type">ReplicaManager</span> = _replicaManager<br><br>	<span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">startup</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>		<span class="hljs-comment">// ...</span><br>		<span class="hljs-comment">// Create and start the socket server acceptor threads so that the bound port is known.</span><br>    <span class="hljs-comment">// Delay starting processors until the end of the initialization sequence to ensure</span><br>    <span class="hljs-comment">// that credentials have been loaded before processing authentications.</span><br>    socketServer = <span class="hljs-keyword">new</span> <span class="hljs-type">SocketServer</span>(config, metrics, time, credentialProvider, apiVersionManager)<br>		<span class="hljs-comment">// ...</span><br>		<span class="hljs-comment">// Enable inbound TCP connections. Each endpoint will be started only once its matching</span><br>    <span class="hljs-comment">// authorizer future is completed.</span><br>    socketServer.enableRequestProcessing(authorizerFutures)<br><br>		<span class="hljs-comment">// ...</span><br>		<span class="hljs-comment">// Create the request processor objects.</span><br>      <span class="hljs-keyword">val</span> raftSupport = <span class="hljs-type">RaftSupport</span>(forwardingManager, metadataCache)<br>      dataPlaneRequestProcessor = <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaApis</span>(<br>        requestChannel = socketServer.dataPlaneRequestChannel,<br>        metadataSupport = raftSupport,<br>        replicaManager = replicaManager,<br>        groupCoordinator = groupCoordinator,<br>        txnCoordinator = transactionCoordinator,<br>        autoTopicCreationManager = autoTopicCreationManager,<br>        brokerId = config.nodeId,<br>        config = config,<br>        configRepository = metadataCache,<br>        metadataCache = metadataCache,<br>        metrics = metrics,<br>        authorizer = authorizer,<br>        quotas = quotaManagers,<br>        fetchManager = fetchManager,<br>        brokerTopicStats = brokerTopicStats,<br>        clusterId = clusterId,<br>        time = time,<br>        tokenManager = tokenManager,<br>        apiVersionManager = apiVersionManager)<br><br>      dataPlaneRequestHandlerPool = <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaRequestHandlerPool</span>(config.nodeId,<br>        socketServer.dataPlaneRequestChannel, dataPlaneRequestProcessor, time,<br>        config.numIoThreads, <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;DataPlaneAcceptor.MetricPrefix&#125;</span>RequestHandlerAvgIdlePercent&quot;</span>,<br>        <span class="hljs-type">DataPlaneAcceptor</span>.<span class="hljs-type">ThreadPrefix</span>)<br>	&#125;<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">trait</span> <span class="hljs-title">KafkaBroker</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dataPlaneRequestHandlerPool</span></span>: <span class="hljs-type">KafkaRequestHandlerPool</span><br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="SocketServer-enableRequestProcessing"><a href="#SocketServer-enableRequestProcessing" class="headerlink" title="SocketServer#enableRequestProcessing()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/network/SocketServer.scala?L193">SocketServer#enableRequestProcessing()</a></h3><p>Kafka 的 data plane 支持监听多个端口，每个端口即一个 EndPoint</p>
<ol>
<li>每个 EndPoint 对应一个 DataPlaneAcceptor 用于接收客户端请求创建连接</li>
<li>DataPlaneAcceptor 对应多个 Processor, acceptor 将连接均匀地分配给 processors 处理连接的读写 I&#x2F;O</li>
<li>读取到一个完整请求后将请求通过 dataPlaneRequestChannel 传递给 KafkaApis 独立的线程处理</li>
<li>处理完成产生响应，再由 Processor 将响应报文写回请求连接</li>
</ol>
<p>除了 data plane, 还有 control plane acceptor  用于处理控制面请求，其只对应一个 processor</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Handles new connections, requests and responses to and from broker.</span><br><span class="hljs-comment"> * Kafka supports two types of request planes :</span><br><span class="hljs-comment"> *  - data-plane :</span><br><span class="hljs-comment"> *    - Handles requests from clients and other brokers in the cluster.</span><br><span class="hljs-comment"> *    - The threading model is</span><br><span class="hljs-comment"> *      1 Acceptor thread per listener, that handles new connections.</span><br><span class="hljs-comment"> *      It is possible to configure multiple data-planes by specifying multiple &quot;,&quot; separated endpoints for &quot;listeners&quot; in KafkaConfig.</span><br><span class="hljs-comment"> *      Acceptor has N Processor threads that each have their own selector and read requests from sockets</span><br><span class="hljs-comment"> *      M Handler threads that handle requests and produce responses back to the processor threads for writing.</span><br><span class="hljs-comment"> *  - control-plane :</span><br><span class="hljs-comment"> *    - Handles requests from controller. This is optional and can be configured by specifying &quot;control.plane.listener.name&quot;.</span><br><span class="hljs-comment"> *      If not configured, the controller requests are handled by the data-plane.</span><br><span class="hljs-comment"> *    - The threading model is</span><br><span class="hljs-comment"> *      1 Acceptor thread that handles new connections</span><br><span class="hljs-comment"> *      Acceptor has 1 Processor thread that has its own selector and read requests from the socket.</span><br><span class="hljs-comment"> *      1 Handler thread that handles requests and produces responses back to the processor thread for writing.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SocketServer</span>(<span class="hljs-params">...</span>) </span>&#123;<br>	<span class="hljs-comment">// data-plane</span><br>  <span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">val</span> dataPlaneAcceptors = <span class="hljs-keyword">new</span> <span class="hljs-type">ConcurrentHashMap</span>[<span class="hljs-type">EndPoint</span>, <span class="hljs-type">DataPlaneAcceptor</span>]()<br>  <span class="hljs-keyword">val</span> dataPlaneRequestChannel = <span class="hljs-keyword">new</span> <span class="hljs-type">RequestChannel</span>(maxQueuedRequests, <span class="hljs-type">DataPlaneAcceptor</span>.<span class="hljs-type">MetricPrefix</span>, time, apiVersionManager.newRequestMetrics)<br>  <span class="hljs-comment">// control-plane</span><br>  <span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">var</span> controlPlaneAcceptorOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">ControlPlaneAcceptor</span>] = <span class="hljs-type">None</span><br>  <span class="hljs-keyword">val</span> controlPlaneRequestChannelOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">RequestChannel</span>] = config.controlPlaneListenerName.map(_ =&gt;<br>    <span class="hljs-keyword">new</span> <span class="hljs-type">RequestChannel</span>(<span class="hljs-number">20</span>, <span class="hljs-type">ControlPlaneAcceptor</span>.<span class="hljs-type">MetricPrefix</span>, time, apiVersionManager.newRequestMetrics))<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * A future which is completed once all the authorizer futures are complete.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> allAuthorizerFuturesComplete = <span class="hljs-keyword">new</span> <span class="hljs-type">CompletableFuture</span>[<span class="hljs-type">Void</span>]<br><br>	<span class="hljs-comment">// ...</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">enableRequestProcessing</span></span>(authorizerFutures: <span class="hljs-type">Map</span>[<span class="hljs-type">Endpoint</span>, <span class="hljs-type">CompletableFuture</span>[<span class="hljs-type">Void</span>]]): <span class="hljs-type">Unit</span> = <span class="hljs-keyword">this</span>.synchronized &#123;<br>		<span class="hljs-comment">// ...</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">chainAcceptorFuture</span></span>(acceptor: <span class="hljs-type">Acceptor</span>): <span class="hljs-type">Unit</span> = &#123;<br>      <span class="hljs-comment">// Because of ephemeral ports, we need to **match acceptors to futures by looking at**</span><br>      <span class="hljs-comment">// **the listener name**, rather than the endpoint object.</span><br>      authorizerFutures.find &#123;<br>        <span class="hljs-keyword">case</span> (endpoint, _) =&gt; acceptor.endPoint.listenerName.value().equals(endpoint.listenerName().get())<br>      &#125; <span class="hljs-keyword">match</span> &#123;<br>				<span class="hljs-comment">// **acceptor.startFuture() calls aceeptor.run() which override Thread#run()**</span><br>        <span class="hljs-keyword">case</span> <span class="hljs-type">None</span> =&gt; chainFuture(allAuthorizerFuturesComplete, acceptor.startFuture)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">Some</span>((_, future)) =&gt; chainFuture(future, acceptor.startFuture)<br>      &#125;<br>    &#125;<br><br>    controlPlaneAcceptorOpt.foreach(chainAcceptorFuture)<br>    dataPlaneAcceptors.values().forEach(chainAcceptorFuture)<br>    chainFuture(<span class="hljs-type">CompletableFuture</span>.allOf(authorizerFutures.values.toArray: _*),<br>        allAuthorizerFuturesComplete)<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">chainFuture</span></span>(sourceFuture: <span class="hljs-type">CompletableFuture</span>[<span class="hljs-type">Void</span>], destinationFuture: <span class="hljs-type">CompletableFuture</span>[<span class="hljs-type">Void</span>]): <span class="hljs-type">Unit</span> = &#123;<br>    sourceFuture.whenComplete((_, t) =&gt; <span class="hljs-keyword">if</span> (t != <span class="hljs-literal">null</span>) &#123;<br>      destinationFuture.completeExceptionally(t)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      destinationFuture.complete(<span class="hljs-literal">null</span>)<br>    &#125;)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/network/SocketServer.scala?L594">Acceptor#startFuture</a></p>
<ol>
<li>BrokerServer 将 data plane acceptors 和 control plane acceptor 串在 allAuthorizerFuturesComplete 下启动调用 Acceptor#startFuture()</li>
<li>acceptor 初始化时创建一个 non-daemon thread </li>
<li>startFuture() 先通过 thread.start() 启动所有 processors 线程，再启动 acceptor 线程监听 EndPoint 端口接收客户请求连接</li>
<li>thread.start() 在对应的线程中运行 thread.run(), Acceptor 继承了 Runnable 并重写了 run() 方法，在创建 thread 时将自己作为 runnable 对象传入</li>
<li>Acceptor#run() 在 while(shouldRun.get()) 循环中不断创建连接，处理请求，关闭连接</li>
<li>acceptNewConnections() → assignNewConnection() → Processor#accept()</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Thread that accepts and configures new connections. There is one of these per endpoint.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span>[kafka] <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Acceptor</span>(<span class="hljs-params">...</span>)<span class="hljs-keyword">extends</span> <span class="hljs-title">Runnable</span> <span class="hljs-keyword">with</span> <span class="hljs-title">Logging</span> <span class="hljs-keyword">with</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br>	<span class="hljs-comment">// using java.nio.channels.Selector</span><br>	<span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> nioSelector = <span class="hljs-type">NSelector</span>.open()<br>	<span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">val</span> serverChannel = openServerSocket(endPoint.host, endPoint.port, listenBacklogSize)<br>  <span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">val</span> processors = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayBuffer</span>[<span class="hljs-type">Processor</span>]()<br>	<span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">val</span> startFuture = <span class="hljs-keyword">new</span> <span class="hljs-type">CompletableFuture</span>[<span class="hljs-type">Void</span>]()<br>	<span class="hljs-comment">// acceptor thread</span><br>	<span class="hljs-keyword">val</span> thread = <span class="hljs-type">KafkaThread</span>.nonDaemon(<br>    <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;threadPrefix()&#125;</span>-kafka-socket-acceptor-<span class="hljs-subst">$&#123;endPoint.listenerName&#125;</span>-<span class="hljs-subst">$&#123;endPoint.securityProtocol&#125;</span>-<span class="hljs-subst">$&#123;endPoint.port&#125;</span>&quot;</span>,<br>    <span class="hljs-keyword">this</span>)<br><br>  startFuture.thenRun(() =&gt; synchronized &#123;<br>    <span class="hljs-keyword">if</span> (!shouldRun.get()) &#123;<br>      debug(<span class="hljs-string">s&quot;Ignoring start future for <span class="hljs-subst">$&#123;endPoint.listenerName&#125;</span> since the acceptor has already been shut down.&quot;</span>)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      debug(<span class="hljs-string">s&quot;Starting processors for listener <span class="hljs-subst">$&#123;endPoint.listenerName&#125;</span>&quot;</span>)<br>      started = <span class="hljs-literal">true</span><br>      processors.foreach(_.start())<br>      debug(<span class="hljs-string">s&quot;Starting acceptor thread for listener <span class="hljs-subst">$&#123;endPoint.listenerName&#125;</span>&quot;</span>)<br>      thread.start()<br>    &#125;<br>  &#125;)<br><br>	<span class="hljs-comment">// Create acceptors and processors for the statically configured endpoints when the</span><br>  <span class="hljs-comment">// SocketServer is constructed. Note that this just opens the ports and creates the data</span><br>  <span class="hljs-comment">// structures. It does not start the acceptors and processors or their associated JVM</span><br>  <span class="hljs-comment">// threads.</span><br>  <span class="hljs-keyword">if</span> (apiVersionManager.listenerType.equals(<span class="hljs-type">ListenerType</span>.<span class="hljs-type">CONTROLLER</span>)) &#123;<br>    config.controllerListeners.foreach(createDataPlaneAcceptorAndProcessors)<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    config.controlPlaneListener.foreach(createControlPlaneAcceptorAndProcessor)<br>    config.dataPlaneListeners.foreach(createDataPlaneAcceptorAndProcessors)<br>  &#125;<br><br>  <span class="hljs-comment">// Processors are now created by each Acceptor. However to preserve compatibility, we need to number the processors</span><br>  <span class="hljs-comment">// globally, so we keep the nextProcessorId counter in SocketServer</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nextProcessorId</span></span>(): <span class="hljs-type">Int</span> = &#123;<br>    nextProcessorId.getAndIncrement()<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Accept loop that checks for new connection attempts</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    serverChannel.register(nioSelector, <span class="hljs-type">SelectionKey</span>.<span class="hljs-type">OP_ACCEPT</span>)<br>    <span class="hljs-keyword">while</span> (shouldRun.get()) &#123;<br>			<span class="hljs-comment">// ...</span><br>      acceptNewConnections()<br>      closeThrottledConnections()<br>			<span class="hljs-comment">// ...</span><br>		&#125;<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Create a server socket to listen for connections on.</span><br><span class="hljs-comment">   */</span><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">openServerSocket</span></span>(host: <span class="hljs-type">String</span>, port: <span class="hljs-type">Int</span>, listenBacklogSize: <span class="hljs-type">Int</span>): <span class="hljs-type">ServerSocketChannel</span> = &#123;<br>    <span class="hljs-keyword">val</span> socketAddress = <span class="hljs-keyword">new</span> <span class="hljs-type">InetSocketAddress</span>(host, port)<br>    <span class="hljs-keyword">val</span> serverChannel = <span class="hljs-type">ServerSocketChannel</span>.open()<br>    serverChannel.configureBlocking(<span class="hljs-literal">false</span>)<br>    serverChannel.socket().setReceiveBufferSize(recvBufferSize)<br>    serverChannel.socket.bind(socketAddress, listenBacklogSize)<br>    serverChannel<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Listen for new connections and assign accepted connections to processors using round-robin.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">acceptNewConnections</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> ready = nioSelector.select(<span class="hljs-number">500</span>)<br>    <span class="hljs-keyword">if</span> (ready &gt; <span class="hljs-number">0</span>) &#123;<br>      <span class="hljs-keyword">val</span> keys = nioSelector.selectedKeys()<br>      <span class="hljs-keyword">val</span> iter = keys.iterator()<br>      <span class="hljs-keyword">while</span> (iter.hasNext &amp;&amp; shouldRun.get()) &#123;<br>        <span class="hljs-keyword">val</span> key = iter.next<br>        iter.remove()<br><br>        <span class="hljs-keyword">if</span> (key.isAcceptable) &#123;<br>          accept(key).foreach &#123; socketChannel =&gt;<br>            <span class="hljs-comment">// Assign the channel to the next processor (using round-robin) to which the</span><br>            <span class="hljs-comment">// channel can be added without blocking. If newConnections queue is full on</span><br>            <span class="hljs-comment">// all processors, block until the last one is able to accept a connection.</span><br>            <span class="hljs-keyword">var</span> retriesLeft = synchronized(processors.length)<br>            <span class="hljs-keyword">var</span> processor: <span class="hljs-type">Processor</span> = <span class="hljs-literal">null</span><br>            <span class="hljs-keyword">do</span> &#123;<br>              retriesLeft -= <span class="hljs-number">1</span><br>              processor = synchronized &#123;<br>                <span class="hljs-comment">// adjust the index (if necessary) and retrieve the processor atomically for</span><br>                <span class="hljs-comment">// correct behaviour in case the number of processors is reduced dynamically</span><br>                currentProcessorIndex = currentProcessorIndex % processors.length<br>                processors(currentProcessorIndex)<br>              &#125;<br>              currentProcessorIndex += <span class="hljs-number">1</span> <span class="hljs-comment">// **processors load balancing**</span><br>            &#125; <span class="hljs-keyword">while</span> (!assignNewConnection(socketChannel, processor, retriesLeft == <span class="hljs-number">0</span>))<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Accept a new connection</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">accept</span></span>(key: <span class="hljs-type">SelectionKey</span>): <span class="hljs-type">Option</span>[<span class="hljs-type">SocketChannel</span>] = &#123;<br>    <span class="hljs-keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="hljs-type">ServerSocketChannel</span>]<br>    <span class="hljs-keyword">val</span> socketChannel = serverSocketChannel.accept()<br>    configureAcceptedSocketChannel(socketChannel)<br>    <span class="hljs-type">Some</span>(socketChannel)<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">assignNewConnection</span></span>(socketChannel: <span class="hljs-type">SocketChannel</span>, processor: <span class="hljs-type">Processor</span>, mayBlock: <span class="hljs-type">Boolean</span>): <span class="hljs-type">Boolean</span> = &#123;<br>    <span class="hljs-keyword">if</span> (processor.accept(socketChannel, mayBlock, blockedPercentMeter)) &#123;<br>      debug(<span class="hljs-string">s&quot;Accepted connection from <span class="hljs-subst">$&#123;socketChannel.socket.getRemoteSocketAddress&#125;</span> on&quot;</span> +<br>        <span class="hljs-string">s&quot; <span class="hljs-subst">$&#123;socketChannel.socket.getLocalSocketAddress&#125;</span> and assigned it to processor <span class="hljs-subst">$&#123;processor.id&#125;</span>,&quot;</span> +<br>        <span class="hljs-string">s&quot; sendBufferSize [actual|requested]: [<span class="hljs-subst">$&#123;socketChannel.socket.getSendBufferSize&#125;</span>|<span class="hljs-subst">$sendBufferSize</span>]&quot;</span> +<br>        <span class="hljs-string">s&quot; recvBufferSize [actual|requested]: [<span class="hljs-subst">$&#123;socketChannel.socket.getReceiveBufferSize&#125;</span>|<span class="hljs-subst">$recvBufferSize</span>]&quot;</span>)<br>      <span class="hljs-literal">true</span><br>    &#125; <span class="hljs-keyword">else</span><br>      <span class="hljs-literal">false</span><br>  &#125;<br><br>	<span class="hljs-keyword">protected</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">configureAcceptedSocketChannel</span></span>(socketChannel: <span class="hljs-type">SocketChannel</span>): <span class="hljs-type">Unit</span> = &#123;<br>    socketChannel.configureBlocking(<span class="hljs-literal">false</span>)<br>    socketChannel.socket().setTcpNoDelay(<span class="hljs-literal">true</span>)<br>    socketChannel.socket().setKeepAlive(<span class="hljs-literal">true</span>)<br>    <span class="hljs-keyword">if</span> (sendBufferSize != <span class="hljs-type">Selectable</span>.<span class="hljs-type">USE_DEFAULT_BUFFER_SIZE</span>)<br>      socketChannel.socket().setSendBufferSize(sendBufferSize)<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Close sockets for any connections that have been throttled.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">closeThrottledConnections</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> timeMs = time.milliseconds<br>    <span class="hljs-keyword">while</span> (throttledSockets.headOption.exists(_.endThrottleTimeMs &lt; timeMs)) &#123;<br>      <span class="hljs-keyword">val</span> closingSocket = throttledSockets.dequeue()<br>      debug(<span class="hljs-string">s&quot;Closing socket from ip <span class="hljs-subst">$&#123;closingSocket.socket.getRemoteAddress&#125;</span>&quot;</span>)<br>      closeSocket(closingSocket.socket, <span class="hljs-keyword">this</span>)<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Wakeup the thread for selection.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wakeup</span></span>(): <span class="hljs-type">Unit</span> = nioSelector.wakeup()<br><br>	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">addProcessors</span></span>(toCreate: <span class="hljs-type">Int</span>): <span class="hljs-type">Unit</span> = synchronized &#123;<br>    <span class="hljs-keyword">val</span> listenerName = endPoint.listenerName<br>    <span class="hljs-keyword">val</span> securityProtocol = endPoint.securityProtocol<br>    <span class="hljs-keyword">val</span> listenerProcessors = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayBuffer</span>[<span class="hljs-type">Processor</span>]()<br><br>    <span class="hljs-keyword">for</span> (_ &lt;- <span class="hljs-number">0</span> until toCreate) &#123;<br>      <span class="hljs-keyword">val</span> processor = newProcessor(socketServer.nextProcessorId(), listenerName, securityProtocol)<br>      listenerProcessors += processor<br>      requestChannel.addProcessor(processor)<br><br>      <span class="hljs-keyword">if</span> (started) &#123;<br>        processor.start()<br>      &#125;<br>    &#125;<br>    processors ++= listenerProcessors<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="Processor-accept"><a href="#Processor-accept" class="headerlink" title="Processor#accept()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/network/SocketServer.scala?L1202">Processor#accept()</a></h3><ol>
<li>Acceptor 将接收的 SocketChannel 通过 Processor#accept() 方法传给 Processor 线程处理</li>
<li>accept() 将 SocketChannel 入列到 newConnections 这个阻塞队列中</li>
<li>run() 从 newConnections 队列取 SocketChannel 进行处理</li>
<li>run() 用 org.apache.kafka.common.network.Selector 对管理的连接进行 I&#x2F;O  multiplexing</li>
<li>接收请求时，监听到 Selector 中的 SocketChannel read ready, 读出一个完整的请求，放到 SocketServer 的 RequestChannel#sendRequest()  队列中由逻辑线程异步处理</li>
<li>请求处理完成且监听到 Selector 中对应的 SocketChannel write ready, 将请求响应写回 SocketChannel</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Thread that processes all requests from a single connection. There are N of these running in parallel</span><br><span class="hljs-comment"> * each of which has its own selector</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @param isPrivilegedListener The privileged listener flag is used as one factor to determine whether</span><br><span class="hljs-comment"> *                             a certain request is forwarded or not. When the control plane is defined,</span><br><span class="hljs-comment"> *                             the control plane processor would be fellow broker&#x27;s choice for sending</span><br><span class="hljs-comment"> *                             forwarding requests; if the control plane is not defined, the processor</span><br><span class="hljs-comment"> *                             relying on the inter broker listener would be acting as the privileged listener.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span>[kafka] <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Processor</span>(<span class="hljs-params">... requestChannel: <span class="hljs-type">RequestChannel</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">Runnable</span> <span class="hljs-keyword">with</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br>  <span class="hljs-keyword">val</span> shouldRun = <span class="hljs-keyword">new</span> <span class="hljs-type">AtomicBoolean</span>(<span class="hljs-literal">true</span>)<br>  <span class="hljs-keyword">val</span> thread = <span class="hljs-type">KafkaThread</span>.nonDaemon(threadName, <span class="hljs-keyword">this</span>)<br><br>	<span class="hljs-comment">// accept() put SocketChannel to this queue, run() process SocketChannel from this queue</span><br>	<span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> newConnections = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayBlockingQueue</span>[<span class="hljs-type">SocketChannel</span>](connectionQueueSize)<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> inflightResponses = mutable.<span class="hljs-type">Map</span>[<span class="hljs-type">String</span>, <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Response</span>]()<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> responseQueue = <span class="hljs-keyword">new</span> <span class="hljs-type">LinkedBlockingDeque</span>[<span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Response</span>]()<br><br>	<span class="hljs-comment">// using org.apache.kafka.common.network.Selector</span><br>	<span class="hljs-keyword">private</span>[network] <span class="hljs-keyword">val</span> selector = <span class="hljs-keyword">new</span> <span class="hljs-type">Selector</span>(...)<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Queue up a new connection for reading</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">accept</span></span>(socketChannel: <span class="hljs-type">SocketChannel</span>,<br>             mayBlock: <span class="hljs-type">Boolean</span>,<br>             acceptorIdlePercentMeter: com.yammer.metrics.core.<span class="hljs-type">Meter</span>): <span class="hljs-type">Boolean</span> = &#123;<br>    newConnections.put(socketChannel)<br>    wakeup()<br>    <span class="hljs-literal">true</span><br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Wakeup the thread for selection.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wakeup</span></span>(): <span class="hljs-type">Unit</span> = selector.wakeup()<br><br>	<span class="hljs-comment">// Connection ids have the format `localAddr:localPort-remoteAddr:remotePort-index`. The index is a</span><br>  <span class="hljs-comment">// non-negative incrementing value that ensures that even if remotePort is reused after a connection is</span><br>  <span class="hljs-comment">// closed, connection ids are not reused while requests from the closed connection are being processed.</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> nextConnectionIndex = <span class="hljs-number">0</span><br><br>	<span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">while</span> (shouldRun.get()) &#123;<br>      <span class="hljs-comment">// setup any new connections that have been queued up</span><br>      configureNewConnections()<br>      <span class="hljs-comment">// register any new responses for writing</span><br>      processNewResponses()<br>      poll()<br>      processCompletedReceives()<br>      processCompletedSends()<br>      processDisconnected()<br>      closeExcessConnections()<br>		&#125;<br>  &#125;<br><br>	<span class="hljs-keyword">val</span> <span class="hljs-type">ConnectionQueueSize</span> = <span class="hljs-number">20</span><br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Register any new connections that have been queued up. The number of connections processed</span><br><span class="hljs-comment">   * in each iteration is limited to ensure that traffic and connection close notifications of</span><br><span class="hljs-comment">   * existing channels are handled promptly.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">configureNewConnections</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">var</span> connectionsProcessed = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> (connectionsProcessed &lt; connectionQueueSize &amp;&amp; !newConnections.isEmpty) &#123;<br>      <span class="hljs-keyword">val</span> channel = newConnections.poll()<br>      selector.register(connectionId(channel.socket), channel)<br>      connectionsProcessed += <span class="hljs-number">1</span><br>    &#125;<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processNewResponses</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">var</span> currentResponse: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Response</span> = <span class="hljs-literal">null</span><br>    <span class="hljs-keyword">while</span> (&#123;currentResponse = dequeueResponse(); currentResponse != <span class="hljs-literal">null</span>&#125;) &#123;<br>      <span class="hljs-keyword">val</span> channelId = currentResponse.request.context.connectionId<br>      currentResponse <span class="hljs-keyword">match</span> &#123;<br>        <span class="hljs-keyword">case</span> response: <span class="hljs-type">NoOpResponse</span> =&gt;<br>          <span class="hljs-comment">// There is no response to send to the client, we need to read more pipelined requests</span><br>          <span class="hljs-comment">// that are sitting in the server&#x27;s socket buffer</span><br>          updateRequestMetrics(response)<br>          trace(<span class="hljs-string">s&quot;Socket server received empty response to send, registering for read: <span class="hljs-subst">$response</span>&quot;</span>)<br>          <span class="hljs-comment">// Try unmuting the channel. If there was no quota violation and the channel has not been throttled,</span><br>          <span class="hljs-comment">// it will be unmuted immediately. If the channel has been throttled, it will be unmuted only if the</span><br>          <span class="hljs-comment">// throttling delay has already passed by now.</span><br>          handleChannelMuteEvent(channelId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">RESPONSE_SENT</span>)<br>          tryUnmuteChannel(channelId)<br><br>        <span class="hljs-keyword">case</span> response: <span class="hljs-type">SendResponse</span> =&gt;<br>          sendResponse(response, response.responseSend)<br>        <span class="hljs-keyword">case</span> response: <span class="hljs-type">CloseConnectionResponse</span> =&gt;<br>          updateRequestMetrics(response)<br>          trace(<span class="hljs-string">&quot;Closing socket connection actively according to the response code.&quot;</span>)<br>          close(channelId)<br>        <span class="hljs-keyword">case</span> _: <span class="hljs-type">StartThrottlingResponse</span> =&gt;<br>          handleChannelMuteEvent(channelId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">THROTTLE_STARTED</span>)<br>        <span class="hljs-keyword">case</span> _: <span class="hljs-type">EndThrottlingResponse</span> =&gt;<br>          <span class="hljs-comment">// Try unmuting the channel. The channel will be unmuted only if the response has already been sent out to</span><br>          <span class="hljs-comment">// the client.</span><br>          handleChannelMuteEvent(channelId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">THROTTLE_ENDED</span>)<br>          tryUnmuteChannel(channelId)<br>        <span class="hljs-keyword">case</span> _ =&gt;<br>          <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalArgumentException</span>(<span class="hljs-string">s&quot;Unknown response type: <span class="hljs-subst">$&#123;currentResponse.getClass&#125;</span>&quot;</span>)<br>      &#125;<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">poll</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> pollTimeout = <span class="hljs-keyword">if</span> (newConnections.isEmpty) <span class="hljs-number">300</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">try</span> selector.poll(pollTimeout)<br>    <span class="hljs-keyword">catch</span> &#123;<br>      <span class="hljs-keyword">case</span> e @ (_: <span class="hljs-type">IllegalStateException</span> | _: <span class="hljs-type">IOException</span>) =&gt;<br>        <span class="hljs-comment">// The exception is not re-thrown and any completed sends/receives/connections/disconnections</span><br>        <span class="hljs-comment">// from this poll will be processed.</span><br>        error(<span class="hljs-string">s&quot;Processor <span class="hljs-subst">$id</span> poll failed&quot;</span>, e)<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processCompletedReceives</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    selector.completedReceives.forEach &#123; receive =&gt;<br>      <span class="hljs-keyword">try</span> &#123;<br>        openOrClosingChannel(receive.source) <span class="hljs-keyword">match</span> &#123;<br>          <span class="hljs-keyword">case</span> <span class="hljs-type">Some</span>(channel) =&gt;<br>            <span class="hljs-keyword">val</span> header = parseRequestHeader(receive.payload)<br>            <span class="hljs-keyword">if</span> (header.apiKey == <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">SASL_HANDSHAKE</span> &amp;&amp; channel.maybeBeginServerReauthentication(receive,<br>              () =&gt; time.nanoseconds()))<br>              trace(<span class="hljs-string">s&quot;Begin re-authentication: <span class="hljs-subst">$channel</span>&quot;</span>)<br>            <span class="hljs-keyword">else</span> &#123;<br>              <span class="hljs-keyword">val</span> nowNanos = time.nanoseconds()<br>              <span class="hljs-keyword">if</span> (channel.serverAuthenticationSessionExpired(nowNanos)) &#123;<br>                <span class="hljs-comment">// be sure to decrease connection count and drop any in-flight responses</span><br>                debug(<span class="hljs-string">s&quot;Disconnecting expired channel: <span class="hljs-subst">$channel</span> : <span class="hljs-subst">$header</span>&quot;</span>)<br>                close(channel.id)<br>                expiredConnectionsKilledCount.record(<span class="hljs-literal">null</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>              &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">val</span> connectionId = receive.source<br>                <span class="hljs-keyword">val</span> context = <span class="hljs-keyword">new</span> <span class="hljs-type">RequestContext</span>(header, connectionId, channel.socketAddress,<br>                  channel.principal, listenerName, securityProtocol,<br>                  channel.channelMetadataRegistry.clientInformation, isPrivilegedListener, channel.principalSerde)<br><br>                <span class="hljs-keyword">val</span> req = <span class="hljs-keyword">new</span> <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>(processor = id, context = context,<br>                  startTimeNanos = nowNanos, memoryPool, receive.payload, requestChannel.metrics, <span class="hljs-type">None</span>)<br><br>                <span class="hljs-comment">// KIP-511: ApiVersionsRequest is intercepted here to catch the client software name</span><br>                <span class="hljs-comment">// and version. It is done here to avoid wiring things up to the api layer.</span><br>                <span class="hljs-keyword">if</span> (header.apiKey == <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">API_VERSIONS</span>) &#123;<br>                  <span class="hljs-keyword">val</span> apiVersionsRequest = req.body[<span class="hljs-type">ApiVersionsRequest</span>]<br>                  <span class="hljs-keyword">if</span> (apiVersionsRequest.isValid) &#123;<br>                    channel.channelMetadataRegistry.registerClientInformation(<span class="hljs-keyword">new</span> <span class="hljs-type">ClientInformation</span>(<br>                      apiVersionsRequest.data.clientSoftwareName,<br>                      apiVersionsRequest.data.clientSoftwareVersion))<br>                  &#125;<br>                &#125;<br><br>								<span class="hljs-comment">// ********************************* put request to blocking queue *********************************</span><br>                requestChannel.sendRequest(req)<br><br>                selector.mute(connectionId)<br>                handleChannelMuteEvent(connectionId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">REQUEST_RECEIVED</span>)<br>              &#125;<br>            &#125;<br>          <span class="hljs-keyword">case</span> <span class="hljs-type">None</span> =&gt;<br>            <span class="hljs-comment">// This should never happen since completed receives are processed immediately after `poll()`</span><br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;Channel <span class="hljs-subst">$&#123;receive.source&#125;</span> removed from selector before processing completed receive&quot;</span>)<br>        &#125;<br>      &#125; <span class="hljs-keyword">catch</span> &#123;<br>        <span class="hljs-comment">// note that even though we got an exception, we can assume that receive.source is valid.</span><br>        <span class="hljs-comment">// Issues with constructing a valid receive object were handled earlier</span><br>        <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt;<br>          processChannelException(receive.source, <span class="hljs-string">s&quot;Exception while processing request from <span class="hljs-subst">$&#123;receive.source&#125;</span>&quot;</span>, e)<br>      &#125;<br>    &#125;<br>    selector.clearCompletedReceives()<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processCompletedSends</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    selector.completedSends.forEach &#123; send =&gt;<br>      <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-keyword">val</span> response = inflightResponses.remove(send.destinationId).getOrElse &#123;<br>          <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;Send for <span class="hljs-subst">$&#123;send.destinationId&#125;</span> completed, but not in `inflightResponses`&quot;</span>)<br>        &#125;<br>        updateRequestMetrics(response)<br><br>        <span class="hljs-comment">// Invoke send completion callback</span><br>        response.onComplete.foreach(onComplete =&gt; onComplete(send))<br><br>        <span class="hljs-comment">// Try unmuting the channel. If there was no quota violation and the channel has not been throttled,</span><br>        <span class="hljs-comment">// it will be unmuted immediately. If the channel has been throttled, it will unmuted only if the throttling</span><br>        <span class="hljs-comment">// delay has already passed by now.</span><br>        handleChannelMuteEvent(send.destinationId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">RESPONSE_SENT</span>)<br>        tryUnmuteChannel(send.destinationId)<br>      &#125; <span class="hljs-keyword">catch</span> &#123;<br>        <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt; processChannelException(send.destinationId,<br>          <span class="hljs-string">s&quot;Exception while processing completed send to <span class="hljs-subst">$&#123;send.destinationId&#125;</span>&quot;</span>, e)<br>      &#125;<br>    &#125;<br>    selector.clearCompletedSends()<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processCompletedSends</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    selector.completedSends.forEach &#123; send =&gt;<br>      <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-keyword">val</span> response = inflightResponses.remove(send.destinationId).getOrElse &#123;<br>          <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;Send for <span class="hljs-subst">$&#123;send.destinationId&#125;</span> completed, but not in `inflightResponses`&quot;</span>)<br>        &#125;<br>        updateRequestMetrics(response)<br><br>        <span class="hljs-comment">// Invoke send completion callback</span><br>        response.onComplete.foreach(onComplete =&gt; onComplete(send))<br><br>        <span class="hljs-comment">// Try unmuting the channel. If there was no quota violation and the channel has not been throttled,</span><br>        <span class="hljs-comment">// it will be unmuted immediately. If the channel has been throttled, it will unmuted only if the throttling</span><br>        <span class="hljs-comment">// delay has already passed by now.</span><br>        handleChannelMuteEvent(send.destinationId, <span class="hljs-type">ChannelMuteEvent</span>.<span class="hljs-type">RESPONSE_SENT</span>)<br>        tryUnmuteChannel(send.destinationId)<br>      &#125; <span class="hljs-keyword">catch</span> &#123;<br>        <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt; processChannelException(send.destinationId,<br>          <span class="hljs-string">s&quot;Exception while processing completed send to <span class="hljs-subst">$&#123;send.destinationId&#125;</span>&quot;</span>, e)<br>      &#125;<br>    &#125;<br>    selector.clearCompletedSends()<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processDisconnected</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    selector.disconnected.keySet.forEach &#123; connectionId =&gt;<br>      <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-keyword">val</span> remoteHost = <span class="hljs-type">ConnectionId</span>.fromString(connectionId).getOrElse &#123;<br>          <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;connectionId has unexpected format: <span class="hljs-subst">$connectionId</span>&quot;</span>)<br>        &#125;.remoteHost<br>        inflightResponses.remove(connectionId).foreach(updateRequestMetrics)<br>        <span class="hljs-comment">// the channel has been closed by the selector but the quotas still need to be updated</span><br>        connectionQuotas.dec(listenerName, <span class="hljs-type">InetAddress</span>.getByName(remoteHost))<br>      &#125; <span class="hljs-keyword">catch</span> &#123;<br>        <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt; processException(<span class="hljs-string">s&quot;Exception while processing disconnection of <span class="hljs-subst">$connectionId</span>&quot;</span>, e)<br>      &#125;<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">closeExcessConnections</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">if</span> (connectionQuotas.maxConnectionsExceeded(listenerName)) &#123;<br>      <span class="hljs-keyword">val</span> channel = selector.lowestPriorityChannel()<br>      <span class="hljs-keyword">if</span> (channel != <span class="hljs-literal">null</span>)<br>        close(channel.id)<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Close the connection identified by `connectionId` and decrement the connection count.</span><br><span class="hljs-comment">   * The channel will be immediately removed from the selector&#x27;s `channels` or `closingChannels`</span><br><span class="hljs-comment">   * and no further disconnect notifications will be sent for this channel by the selector.</span><br><span class="hljs-comment">   * If responses are pending for the channel, they are dropped and metrics is updated.</span><br><span class="hljs-comment">   * If the channel has already been removed from selector, no action is taken.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close</span></span>(connectionId: <span class="hljs-type">String</span>): <span class="hljs-type">Unit</span> = &#123;<br>    openOrClosingChannel(connectionId).foreach &#123; channel =&gt;<br>      debug(<span class="hljs-string">s&quot;Closing selector connection <span class="hljs-subst">$connectionId</span>&quot;</span>)<br>      <span class="hljs-keyword">val</span> address = channel.socketAddress<br>      <span class="hljs-keyword">if</span> (address != <span class="hljs-literal">null</span>)<br>        connectionQuotas.dec(listenerName, address)<br>      selector.close(connectionId)<br><br>      inflightResponses.remove(connectionId).foreach(response =&gt; updateRequestMetrics(response))<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure>

<h3 id="RequestChannel-sendRequest"><a href="#RequestChannel-sendRequest" class="headerlink" title="RequestChannel#sendRequest()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/network/RequestChannel.scala?L376">RequestChannel#sendRequest()</a></h3><ol>
<li>Processor 调用 sendRequest() 将 request 放到队列中，由独立的线程从队列中取出 request 进行处理</li>
<li>KafkaRequestHandler 调用 receiveRequest() 从队列中取出请求进行处理</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Request</span>(<span class="hljs-params">val processor: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val context: <span class="hljs-type">RequestContext</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val startTimeNanos: <span class="hljs-type">Long</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val memoryPool: <span class="hljs-type">MemoryPool</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                @volatile var buffer: <span class="hljs-type">ByteBuffer</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                metrics: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Metrics</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val envelope: <span class="hljs-type">Option</span>[<span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>] = <span class="hljs-type">None</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">BaseRequest</span> </span>&#123;<br>    <span class="hljs-comment">// These need to be volatile because the readers are in the network thread and the writers are in the request</span><br>    <span class="hljs-comment">// handler threads or the purgatory threads</span><br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> requestDequeueTimeNanos = <span class="hljs-number">-1</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> apiLocalCompleteTimeNanos = <span class="hljs-number">-1</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> responseCompleteTimeNanos = <span class="hljs-number">-1</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> responseDequeueTimeNanos = <span class="hljs-number">-1</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> messageConversionsTimeNanos = <span class="hljs-number">0</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> apiThrottleTimeMs = <span class="hljs-number">0</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> temporaryMemoryBytes = <span class="hljs-number">0</span>L<br>    <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> recordNetworkThreadTimeCallback: <span class="hljs-type">Option</span>[<span class="hljs-type">Long</span> =&gt; <span class="hljs-type">Unit</span>] = <span class="hljs-type">None</span><br>		<span class="hljs-comment">// ...</span><br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RequestChannel</span>(<span class="hljs-params">val queueSize: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                     val metricNamePrefix: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                     time: <span class="hljs-type">Time</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                     val metrics: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Metrics</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br>	<span class="hljs-keyword">import</span> <span class="hljs-type">RequestChannel</span>._<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> requestQueue = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayBlockingQueue</span>[<span class="hljs-type">BaseRequest</span>](queueSize)<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> processors = <span class="hljs-keyword">new</span> <span class="hljs-type">ConcurrentHashMap</span>[<span class="hljs-type">Int</span>, <span class="hljs-type">Processor</span>]()<br><br>	<span class="hljs-comment">/** Send a request to be handled, potentially blocking until there is room in the queue for the request */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sendRequest</span></span>(request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>): <span class="hljs-type">Unit</span> = &#123;<br>    requestQueue.put(request)<br>  &#125;<br><br>	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sendResponse</span></span>(<br>    request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>,<br>    response: <span class="hljs-type">AbstractResponse</span>,<br>    onComplete: <span class="hljs-type">Option</span>[<span class="hljs-type">Send</span> =&gt; <span class="hljs-type">Unit</span>]<br>  ): <span class="hljs-type">Unit</span> = &#123;<br>    updateErrorMetrics(request.header.apiKey, response.errorCounts.asScala)<br>    sendResponse(<span class="hljs-keyword">new</span> <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">SendResponse</span>(<br>      request,<br>      request.buildResponseSend(response),<br>      request.responseNode(response),<br>      onComplete<br>    ))<br>  &#125;<br><br>	<span class="hljs-comment">/** Get the next request or block until specified time has elapsed */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">receiveRequest</span></span>(timeout: <span class="hljs-type">Long</span>): <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">BaseRequest</span> =<br>    requestQueue.poll(timeout, <span class="hljs-type">TimeUnit</span>.<span class="hljs-type">MILLISECONDS</span>)<br><br>  <span class="hljs-comment">/** Get the next request or block until there is one */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">receiveRequest</span></span>(): <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">BaseRequest</span> =<br>    requestQueue.take()<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="KafkaRequestHandler-run"><a href="#KafkaRequestHandler-run" class="headerlink" title="KafkaRequestHandler#run()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@f5f8ff0d24ce9f564fe1d7225db7121f22d1b296/-/blob/core/src/main/scala/kafka/server/KafkaRequestHandler.scala?L52">KafkaRequestHandler#run()</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * A thread that answers kafka requests.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaRequestHandler</span>(<span class="hljs-params">id: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          brokerId: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          val aggregateIdleMeter: <span class="hljs-type">Meter</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          val totalHandlerThreads: <span class="hljs-type">AtomicInteger</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          val requestChannel: <span class="hljs-type">RequestChannel</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          apis: <span class="hljs-type">ApiRequestHandler</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                          time: <span class="hljs-type">Time</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">Runnable</span> <span class="hljs-keyword">with</span> <span class="hljs-title">Logging</span> </span>&#123;<br>  <span class="hljs-keyword">this</span>.logIdent = <span class="hljs-string">s&quot;[Kafka Request Handler <span class="hljs-subst">$id</span> on Broker <span class="hljs-subst">$brokerId</span>], &quot;</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> shutdownComplete = <span class="hljs-keyword">new</span> <span class="hljs-type">CountDownLatch</span>(<span class="hljs-number">1</span>)<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> requestLocal = <span class="hljs-type">RequestLocal</span>.withThreadConfinedCaching<br>  <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> stopped = <span class="hljs-literal">false</span><br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">while</span> (!stopped) &#123;<br>      <span class="hljs-comment">// We use a single meter for aggregate idle percentage for the thread pool.</span><br>      <span class="hljs-comment">// Since meter is calculated as total_recorded_value / time_window and</span><br>      <span class="hljs-comment">// time_window is independent of the number of threads, each recorded idle</span><br>      <span class="hljs-comment">// time should be discounted by # threads.</span><br>      <span class="hljs-keyword">val</span> startSelectTime = time.nanoseconds<br><br>      <span class="hljs-keyword">val</span> req = requestChannel.receiveRequest(<span class="hljs-number">300</span>)<br>      <span class="hljs-keyword">val</span> endTime = time.nanoseconds<br>      <span class="hljs-keyword">val</span> idleTime = endTime - startSelectTime<br>      aggregateIdleMeter.mark(idleTime / totalHandlerThreads.get)<br><br>      req <span class="hljs-keyword">match</span> &#123;<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">ShutdownRequest</span> =&gt;<br>          debug(<span class="hljs-string">s&quot;Kafka request handler <span class="hljs-subst">$id</span> on broker <span class="hljs-subst">$brokerId</span> received shut down command&quot;</span>)<br>          completeShutdown()<br>          <span class="hljs-keyword">return</span><br><br>        <span class="hljs-keyword">case</span> request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span> =&gt;<br>          <span class="hljs-keyword">try</span> &#123;<br>            request.requestDequeueTimeNanos = endTime<br>            trace(<span class="hljs-string">s&quot;Kafka request handler <span class="hljs-subst">$id</span> on broker <span class="hljs-subst">$brokerId</span> handling request <span class="hljs-subst">$request</span>&quot;</span>)<br>            apis.handle(request, requestLocal)<br>          &#125; <span class="hljs-keyword">catch</span> &#123;<br>            <span class="hljs-keyword">case</span> e: <span class="hljs-type">FatalExitError</span> =&gt;<br>              completeShutdown()<br>              <span class="hljs-type">Exit</span>.exit(e.statusCode)<br>            <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt; error(<span class="hljs-string">&quot;Exception when handling request&quot;</span>, e)<br>          &#125; <span class="hljs-keyword">finally</span> &#123;<br>            request.releaseBuffer()<br>          &#125;<br><br>        <span class="hljs-keyword">case</span> <span class="hljs-literal">null</span> =&gt; <span class="hljs-comment">// continue</span><br>      &#125;<br>    &#125;<br>    completeShutdown()<br>  &#125;<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaRequestHandlerPool</span>(<span class="hljs-params">val brokerId: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              val requestChannel: <span class="hljs-type">RequestChannel</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              val apis: <span class="hljs-type">ApiRequestHandler</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              time: <span class="hljs-type">Time</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              numThreads: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              requestHandlerAvgIdleMetricName: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                              logAndThreadNamePrefix : <span class="hljs-type">String</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">Logging</span> <span class="hljs-keyword">with</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> threadPoolSize: <span class="hljs-type">AtomicInteger</span> = <span class="hljs-keyword">new</span> <span class="hljs-type">AtomicInteger</span>(numThreads)<br>  <span class="hljs-comment">/* a meter to track the average free capacity of the request handlers */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> aggregateIdleMeter = newMeter(requestHandlerAvgIdleMetricName, <span class="hljs-string">&quot;percent&quot;</span>, <span class="hljs-type">TimeUnit</span>.<span class="hljs-type">NANOSECONDS</span>)<br><br>  <span class="hljs-keyword">this</span>.logIdent = <span class="hljs-string">&quot;[&quot;</span> + logAndThreadNamePrefix + <span class="hljs-string">&quot; Kafka Request Handler on Broker &quot;</span> + brokerId + <span class="hljs-string">&quot;], &quot;</span><br>  <span class="hljs-keyword">val</span> runnables = <span class="hljs-keyword">new</span> mutable.<span class="hljs-type">ArrayBuffer</span>[<span class="hljs-type">KafkaRequestHandler</span>](numThreads)<br>  <span class="hljs-keyword">for</span> (i &lt;- <span class="hljs-number">0</span> until numThreads) &#123;<br>    createHandler(i)<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createHandler</span></span>(id: <span class="hljs-type">Int</span>): <span class="hljs-type">Unit</span> = synchronized &#123;<br>    runnables += <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaRequestHandler</span>(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)<br>    <span class="hljs-type">KafkaThread</span>.daemon(logAndThreadNamePrefix + <span class="hljs-string">&quot;-kafka-request-handler-&quot;</span> + id, runnables(id)).start()<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resizeThreadPool</span></span>(newSize: <span class="hljs-type">Int</span>): <span class="hljs-type">Unit</span> = synchronized &#123;<br>    <span class="hljs-keyword">val</span> currentSize = threadPoolSize.get<br>    info(<span class="hljs-string">s&quot;Resizing request handler thread pool size from <span class="hljs-subst">$currentSize</span> to <span class="hljs-subst">$newSize</span>&quot;</span>)<br>    <span class="hljs-keyword">if</span> (newSize &gt; currentSize) &#123;<br>      <span class="hljs-keyword">for</span> (i &lt;- currentSize until newSize) &#123;<br>        createHandler(i)<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (newSize &lt; currentSize) &#123;<br>      <span class="hljs-keyword">for</span> (i &lt;- <span class="hljs-number">1</span> to (currentSize - newSize)) &#123;<br>        runnables.remove(currentSize - i).stop()<br>      &#125;<br>    &#125;<br>    threadPoolSize.set(newSize)<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shutdown</span></span>(): <span class="hljs-type">Unit</span> = synchronized &#123;<br>    info(<span class="hljs-string">&quot;shutting down&quot;</span>)<br>    <span class="hljs-keyword">for</span> (handler &lt;- runnables)<br>      handler.initiateShutdown()<br>    <span class="hljs-keyword">for</span> (handler &lt;- runnables)<br>      handler.awaitShutdown()<br>    info(<span class="hljs-string">&quot;shut down completely&quot;</span>)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="KafkaApis"><a href="#KafkaApis" class="headerlink" title="KafkaApis"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@f5f8ff0d24ce9f564fe1d7225db7121f22d1b296/-/blob/core/src/main/scala/kafka/server/KafkaApis.scala?L93:7">KafkaApis</a></h3><p>处理 requestChannel 中的请求</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-class"><span class="hljs-keyword">trait</span> <span class="hljs-title">ApiRequestHandler</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handle</span></span>(request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>, requestLocal: <span class="hljs-type">RequestLocal</span>): <span class="hljs-type">Unit</span><br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Logic to handle the various Kafka requests</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaApis</span>(<span class="hljs-params">val requestChannel: <span class="hljs-type">RequestChannel</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val metadataSupport: <span class="hljs-type">MetadataSupport</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val replicaManager: <span class="hljs-type">ReplicaManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val groupCoordinator: <span class="hljs-type">GroupCoordinator</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val txnCoordinator: <span class="hljs-type">TransactionCoordinator</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val autoTopicCreationManager: <span class="hljs-type">AutoTopicCreationManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val brokerId: <span class="hljs-type">Int</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val config: <span class="hljs-type">KafkaConfig</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val configRepository: <span class="hljs-type">ConfigRepository</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val metadataCache: <span class="hljs-type">MetadataCache</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val metrics: <span class="hljs-type">Metrics</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val authorizer: <span class="hljs-type">Option</span>[<span class="hljs-type">Authorizer</span>],</span></span><br><span class="hljs-params"><span class="hljs-class">                val quotas: <span class="hljs-type">QuotaManagers</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val fetchManager: <span class="hljs-type">FetchManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                brokerTopicStats: <span class="hljs-type">BrokerTopicStats</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val clusterId: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                time: <span class="hljs-type">Time</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val tokenManager: <span class="hljs-type">DelegationTokenManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                val apiVersionManager: <span class="hljs-type">ApiVersionManager</span></span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">ApiRequestHandler</span> <span class="hljs-keyword">with</span> <span class="hljs-title">Logging</span> </span>&#123;<br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Top-level method that handles all requests and multiplexes to the right api</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handle</span></span>(request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>, requestLocal: <span class="hljs-type">RequestLocal</span>): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>      trace(<span class="hljs-string">s&quot;Handling request:<span class="hljs-subst">$&#123;request.requestDesc(true)&#125;</span> from connection <span class="hljs-subst">$&#123;request.context.connectionId&#125;</span>;&quot;</span> +<br>        <span class="hljs-string">s&quot;securityProtocol:<span class="hljs-subst">$&#123;request.context.securityProtocol&#125;</span>,principal:<span class="hljs-subst">$&#123;request.context.principal&#125;</span>&quot;</span>)<br><br>      <span class="hljs-keyword">if</span> (!apiVersionManager.isApiEnabled(request.header.apiKey)) &#123;<br>        <span class="hljs-comment">// The socket server will reject APIs which are not exposed in this scope and close the connection</span><br>        <span class="hljs-comment">// before handing them to the request handler, so this path should not be exercised in practice</span><br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;API <span class="hljs-subst">$&#123;request.header.apiKey&#125;</span> is not enabled&quot;</span>)<br>      &#125;<br><br>      request.header.apiKey <span class="hljs-keyword">match</span> &#123;<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">PRODUCE</span> =&gt; handleProduceRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">FETCH</span> =&gt; handleFetchRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LIST_OFFSETS</span> =&gt; handleListOffsetRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">METADATA</span> =&gt; handleTopicMetadataRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">STOP_REPLICA</span> =&gt; handleStopReplicaRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">UPDATE_METADATA</span> =&gt; handleUpdateMetadataRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">CONTROLLED_SHUTDOWN</span> =&gt; handleControlledShutdownRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">OFFSET_COMMIT</span> =&gt; handleOffsetCommitRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">OFFSET_FETCH</span> =&gt; handleOffsetFetchRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">FIND_COORDINATOR</span> =&gt; handleFindCoordinatorRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">JOIN_GROUP</span> =&gt; handleJoinGroupRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">HEARTBEAT</span> =&gt; handleHeartbeatRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LEAVE_GROUP</span> =&gt; handleLeaveGroupRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">SYNC_GROUP</span> =&gt; handleSyncGroupRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_GROUPS</span> =&gt; handleDescribeGroupRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LIST_GROUPS</span> =&gt; handleListGroupsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">SASL_HANDSHAKE</span> =&gt; handleSaslHandshakeRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">API_VERSIONS</span> =&gt; handleApiVersionsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">CREATE_TOPICS</span> =&gt; maybeForwardToController(request, handleCreateTopicsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DELETE_TOPICS</span> =&gt; maybeForwardToController(request, handleDeleteTopicsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DELETE_RECORDS</span> =&gt; handleDeleteRecordsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">INIT_PRODUCER_ID</span> =&gt; handleInitProducerIdRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">OFFSET_FOR_LEADER_EPOCH</span> =&gt; handleOffsetForLeaderEpochRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ADD_PARTITIONS_TO_TXN</span> =&gt; handleAddPartitionToTxnRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ADD_OFFSETS_TO_TXN</span> =&gt; handleAddOffsetsToTxnRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">END_TXN</span> =&gt; handleEndTxnRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">WRITE_TXN_MARKERS</span> =&gt; handleWriteTxnMarkersRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">TXN_OFFSET_COMMIT</span> =&gt; handleTxnOffsetCommitRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_ACLS</span> =&gt; handleDescribeAcls(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">CREATE_ACLS</span> =&gt; maybeForwardToController(request, handleCreateAcls)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DELETE_ACLS</span> =&gt; maybeForwardToController(request, handleDeleteAcls)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_CONFIGS</span> =&gt; handleAlterConfigsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_CONFIGS</span> =&gt; handleDescribeConfigsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_REPLICA_LOG_DIRS</span> =&gt; handleAlterReplicaLogDirsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_LOG_DIRS</span> =&gt; handleDescribeLogDirsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">SASL_AUTHENTICATE</span> =&gt; handleSaslAuthenticateRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">CREATE_PARTITIONS</span> =&gt; maybeForwardToController(request, handleCreatePartitionsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">CREATE_DELEGATION_TOKEN</span> =&gt; maybeForwardToController(request, handleCreateTokenRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">RENEW_DELEGATION_TOKEN</span> =&gt; maybeForwardToController(request, handleRenewTokenRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">EXPIRE_DELEGATION_TOKEN</span> =&gt; maybeForwardToController(request, handleExpireTokenRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_DELEGATION_TOKEN</span> =&gt; handleDescribeTokensRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DELETE_GROUPS</span> =&gt; handleDeleteGroupsRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ELECT_LEADERS</span> =&gt; maybeForwardToController(request, handleElectLeaders)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">INCREMENTAL_ALTER_CONFIGS</span> =&gt; handleIncrementalAlterConfigsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_PARTITION_REASSIGNMENTS</span> =&gt; maybeForwardToController(request, handleAlterPartitionReassignmentsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LIST_PARTITION_REASSIGNMENTS</span> =&gt; maybeForwardToController(request, handleListPartitionReassignmentsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">OFFSET_DELETE</span> =&gt; handleOffsetDeleteRequest(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_CLIENT_QUOTAS</span> =&gt; handleDescribeClientQuotasRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_CLIENT_QUOTAS</span> =&gt; maybeForwardToController(request, handleAlterClientQuotasRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_USER_SCRAM_CREDENTIALS</span> =&gt; handleDescribeUserScramCredentialsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_USER_SCRAM_CREDENTIALS</span> =&gt; maybeForwardToController(request, handleAlterUserScramCredentialsRequest)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALTER_PARTITION</span> =&gt; handleAlterPartitionRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">UPDATE_FEATURES</span> =&gt; maybeForwardToController(request, handleUpdateFeatures)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ENVELOPE</span> =&gt; handleEnvelope(request, requestLocal)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_CLUSTER</span> =&gt; handleDescribeCluster(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_PRODUCERS</span> =&gt; handleDescribeProducersRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">UNREGISTER_BROKER</span> =&gt; forwardToControllerOrFail(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_TRANSACTIONS</span> =&gt; handleDescribeTransactionsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">LIST_TRANSACTIONS</span> =&gt; handleListTransactionsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">ALLOCATE_PRODUCER_IDS</span> =&gt; handleAllocateProducerIdsRequest(request)<br>        <span class="hljs-keyword">case</span> <span class="hljs-type">ApiKeys</span>.<span class="hljs-type">DESCRIBE_QUORUM</span> =&gt; forwardToControllerOrFail(request)<br>        <span class="hljs-keyword">case</span> _ =&gt; <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">s&quot;No handler for request api key <span class="hljs-subst">$&#123;request.header.apiKey&#125;</span>&quot;</span>)<br>      &#125;<br>    &#125; <span class="hljs-keyword">catch</span> &#123;<br>      <span class="hljs-keyword">case</span> e: <span class="hljs-type">FatalExitError</span> =&gt; <span class="hljs-keyword">throw</span> e<br>      <span class="hljs-keyword">case</span> e: <span class="hljs-type">Throwable</span> =&gt;<br>        error(<span class="hljs-string">s&quot;Unexpected error handling request <span class="hljs-subst">$&#123;request.requestDesc(true)&#125;</span> &quot;</span> +<br>          <span class="hljs-string">s&quot;with context <span class="hljs-subst">$&#123;request.context&#125;</span>&quot;</span>, e)<br>        requestHelper.handleError(request, e)<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>      <span class="hljs-comment">// try to complete delayed action. In order to avoid conflicting locking, the actions to complete delayed requests</span><br>      <span class="hljs-comment">// are kept in a queue. We add the logic to check the ReplicaManager queue at the end of KafkaApis.handle() and the</span><br>      <span class="hljs-comment">// expiration thread for certain delayed operations (e.g. DelayedJoin)</span><br>			<span class="hljs-comment">// **************************** trigger write local log ****************************</span><br>      replicaManager.tryCompleteActions()<br>      <span class="hljs-comment">// The local completion time may be set while processing the request. Only record it if it&#x27;s unset.</span><br>      <span class="hljs-keyword">if</span> (request.apiLocalCompleteTimeNanos &lt; <span class="hljs-number">0</span>)<br>        request.apiLocalCompleteTimeNanos = time.nanoseconds<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>其中 handleProducerReuqest 处理生产消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment">  * Handle a produce request</span><br><span class="hljs-comment">  */</span><br> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handleProduceRequest</span></span>(request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>, requestLocal: <span class="hljs-type">RequestLocal</span>): <span class="hljs-type">Unit</span> = &#123;<br>   <span class="hljs-keyword">val</span> produceRequest = request.body[<span class="hljs-type">ProduceRequest</span>]<br>   <span class="hljs-keyword">val</span> requestSize = request.sizeInBytes<br><br>   <span class="hljs-keyword">if</span> (<span class="hljs-type">RequestUtils</span>.hasTransactionalRecords(produceRequest)) &#123;<br>     <span class="hljs-keyword">val</span> isAuthorizedTransactional = produceRequest.transactionalId != <span class="hljs-literal">null</span> &amp;&amp;<br>       authHelper.authorize(request.context, <span class="hljs-type">WRITE</span>, <span class="hljs-type">TRANSACTIONAL_ID</span>, produceRequest.transactionalId)<br>     <span class="hljs-keyword">if</span> (!isAuthorizedTransactional) &#123;<br>       requestHelper.sendErrorResponseMaybeThrottle(request, <span class="hljs-type">Errors</span>.<span class="hljs-type">TRANSACTIONAL_ID_AUTHORIZATION_FAILED</span>.exception)<br>       <span class="hljs-keyword">return</span><br>     &#125;<br>   &#125;<br><br>   <span class="hljs-keyword">val</span> unauthorizedTopicResponses = mutable.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">PartitionResponse</span>]()<br>   <span class="hljs-keyword">val</span> nonExistingTopicResponses = mutable.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">PartitionResponse</span>]()<br>   <span class="hljs-keyword">val</span> invalidRequestResponses = mutable.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">PartitionResponse</span>]()<br>   <span class="hljs-keyword">val</span> authorizedRequestInfo = mutable.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">MemoryRecords</span>]()<br>   <span class="hljs-comment">// cache the result to avoid redundant authorization calls</span><br>   <span class="hljs-keyword">val</span> authorizedTopics = authHelper.filterByAuthorized(request.context, <span class="hljs-type">WRITE</span>, <span class="hljs-type">TOPIC</span>,<br>     produceRequest.data().topicData().asScala)(_.name())<br><br>   produceRequest.data.topicData.forEach(topic =&gt; topic.partitionData.forEach &#123; partition =&gt;<br>     <span class="hljs-keyword">val</span> topicPartition = <span class="hljs-keyword">new</span> <span class="hljs-type">TopicPartition</span>(topic.name, partition.index)<br>     <span class="hljs-comment">// This caller assumes the type is MemoryRecords and that is true on current serialization</span><br>     <span class="hljs-comment">// We cast the type to avoid causing big change to code base.</span><br>     <span class="hljs-comment">// https://issues.apache.org/jira/browse/KAFKA-10698</span><br>     <span class="hljs-keyword">val</span> memoryRecords = partition.records.asInstanceOf[<span class="hljs-type">MemoryRecords</span>]<br>     <span class="hljs-keyword">if</span> (!authorizedTopics.contains(topicPartition.topic))<br>       unauthorizedTopicResponses += topicPartition -&gt; <span class="hljs-keyword">new</span> <span class="hljs-type">PartitionResponse</span>(<span class="hljs-type">Errors</span>.<span class="hljs-type">TOPIC_AUTHORIZATION_FAILED</span>)<br>     <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!metadataCache.contains(topicPartition))<br>       nonExistingTopicResponses += topicPartition -&gt; <span class="hljs-keyword">new</span> <span class="hljs-type">PartitionResponse</span>(<span class="hljs-type">Errors</span>.<span class="hljs-type">UNKNOWN_TOPIC_OR_PARTITION</span>)<br>     <span class="hljs-keyword">else</span><br>       <span class="hljs-keyword">try</span> &#123;<br>         <span class="hljs-type">ProduceRequest</span>.validateRecords(request.header.apiVersion, memoryRecords)<br>         authorizedRequestInfo += (topicPartition -&gt; memoryRecords)<br>       &#125; <span class="hljs-keyword">catch</span> &#123;<br>         <span class="hljs-keyword">case</span> e: <span class="hljs-type">ApiException</span> =&gt;<br>           invalidRequestResponses += topicPartition -&gt; <span class="hljs-keyword">new</span> <span class="hljs-type">PartitionResponse</span>(<span class="hljs-type">Errors</span>.forException(e))<br>       &#125;<br>   &#125;)<br>	<span class="hljs-comment">// the callback for sending a produce response</span><br>   <span class="hljs-comment">// The construction of ProduceResponse is able to accept auto-generated protocol data so</span><br>   <span class="hljs-comment">// KafkaApis#handleProduceRequest should apply auto-generated protocol to avoid extra conversion.</span><br>   <span class="hljs-comment">// https://issues.apache.org/jira/browse/KAFKA-10730</span><br>   <span class="hljs-meta">@nowarn</span>(<span class="hljs-string">&quot;cat=deprecation&quot;</span>)<br>   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sendResponseCallback</span></span>(responseStatus: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">PartitionResponse</span>]): <span class="hljs-type">Unit</span> = &#123;<br>     <span class="hljs-keyword">val</span> mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses ++ invalidRequestResponses<br>     <span class="hljs-keyword">var</span> errorInResponse = <span class="hljs-literal">false</span><br><br>     mergedResponseStatus.forKeyValue &#123; (topicPartition, status) =&gt;<br>       <span class="hljs-keyword">if</span> (status.error != <span class="hljs-type">Errors</span>.<span class="hljs-type">NONE</span>) &#123;<br>         errorInResponse = <span class="hljs-literal">true</span><br>         debug(<span class="hljs-string">&quot;Produce request with correlation id %d from client %s on partition %s failed due to %s&quot;</span>.format(<br>           request.header.correlationId,<br>           request.header.clientId,<br>           topicPartition,<br>           status.error.exceptionName))<br>       &#125;<br>     &#125;<br><br>     <span class="hljs-comment">// Record both bandwidth and request quota-specific values and throttle by muting the channel if any of the quotas</span><br>     <span class="hljs-comment">// have been violated. If both quotas have been violated, use the max throttle time between the two quotas. Note</span><br>     <span class="hljs-comment">// that the request quota is not enforced if acks == 0.</span><br>     <span class="hljs-keyword">val</span> timeMs = time.milliseconds()<br>     <span class="hljs-keyword">val</span> bandwidthThrottleTimeMs = quotas.produce.maybeRecordAndGetThrottleTimeMs(request, requestSize, timeMs)<br>     <span class="hljs-keyword">val</span> requestThrottleTimeMs =<br>       <span class="hljs-keyword">if</span> (produceRequest.acks == <span class="hljs-number">0</span>) <span class="hljs-number">0</span><br>       <span class="hljs-keyword">else</span> quotas.request.maybeRecordAndGetThrottleTimeMs(request, timeMs)<br>     <span class="hljs-keyword">val</span> maxThrottleTimeMs = <span class="hljs-type">Math</span>.max(bandwidthThrottleTimeMs, requestThrottleTimeMs)<br>     <span class="hljs-keyword">if</span> (maxThrottleTimeMs &gt; <span class="hljs-number">0</span>) &#123;<br>       request.apiThrottleTimeMs = maxThrottleTimeMs<br>       <span class="hljs-keyword">if</span> (bandwidthThrottleTimeMs &gt; requestThrottleTimeMs) &#123;<br>         requestHelper.throttle(quotas.produce, request, bandwidthThrottleTimeMs)<br>       &#125; <span class="hljs-keyword">else</span> &#123;<br>         requestHelper.throttle(quotas.request, request, requestThrottleTimeMs)<br>       &#125;<br>     &#125;<br><br>     <span class="hljs-comment">// Send the response immediately. In case of throttling, the channel has already been muted.</span><br>     <span class="hljs-keyword">if</span> (produceRequest.acks == <span class="hljs-number">0</span>) &#123;<br>       <span class="hljs-comment">// no operation needed if producer request.required.acks = 0; however, if there is any error in handling</span><br>       <span class="hljs-comment">// the request, since no response is expected by the producer, the server will close socket server so that</span><br>       <span class="hljs-comment">// the producer client will know that some error has happened and will refresh its metadata</span><br>       <span class="hljs-keyword">if</span> (errorInResponse) &#123;<br>         <span class="hljs-keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="hljs-keyword">case</span> (topicPartition, status) =&gt;<br>           topicPartition -&gt; status.error.exceptionName<br>         &#125;.mkString(<span class="hljs-string">&quot;, &quot;</span>)<br>         info(<br>           <span class="hljs-string">s&quot;Closing connection due to error during produce request with correlation id <span class="hljs-subst">$&#123;request.header.correlationId&#125;</span> &quot;</span> +<br>             <span class="hljs-string">s&quot;from client id <span class="hljs-subst">$&#123;request.header.clientId&#125;</span> with ack=0\n&quot;</span> +<br>             <span class="hljs-string">s&quot;Topic and partition to exceptions: <span class="hljs-subst">$exceptionsSummary</span>&quot;</span><br>         )<br>         requestChannel.closeConnection(request, <span class="hljs-keyword">new</span> <span class="hljs-type">ProduceResponse</span>(mergedResponseStatus.asJava).errorCounts)<br>       &#125; <span class="hljs-keyword">else</span> &#123;<br>         <span class="hljs-comment">// Note that although request throttling is exempt for acks == 0, the channel may be throttled due to</span><br>         <span class="hljs-comment">// bandwidth quota violation.</span><br>         requestHelper.sendNoOpResponseExemptThrottle(request)<br>       &#125;<br>     &#125; <span class="hljs-keyword">else</span> &#123;<br>       requestChannel.sendResponse(request, <span class="hljs-keyword">new</span> <span class="hljs-type">ProduceResponse</span>(mergedResponseStatus.asJava, maxThrottleTimeMs), <span class="hljs-type">None</span>)<br>     &#125;<br>   &#125;<br><br>   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processingStatsCallback</span></span>(processingStats: <span class="hljs-type">FetchResponseStats</span>): <span class="hljs-type">Unit</span> = &#123;<br>     processingStats.forKeyValue &#123; (tp, info) =&gt;<br>       updateRecordConversionStats(request, tp, info)<br>     &#125;<br>   &#125;<br><br>   <span class="hljs-keyword">if</span> (authorizedRequestInfo.isEmpty)<br>     sendResponseCallback(<span class="hljs-type">Map</span>.empty)<br>   <span class="hljs-keyword">else</span> &#123;<br>     <span class="hljs-keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="hljs-type">AdminUtils</span>.<span class="hljs-type">AdminClientId</span><br><br>     <span class="hljs-comment">// call the replica manager to append messages to the replicas</span><br>     replicaManager.appendRecords(<br>       timeout = produceRequest.timeout.toLong,<br>       requiredAcks = produceRequest.acks,<br>       internalTopicsAllowed = internalTopicsAllowed,<br>       origin = <span class="hljs-type">AppendOrigin</span>.<span class="hljs-type">Client</span>,<br>       entriesPerPartition = authorizedRequestInfo,<br>       requestLocal = requestLocal,<br>       responseCallback = sendResponseCallback,<br>       recordConversionStatsCallback = processingStatsCallback)<br><br>     <span class="hljs-comment">// if the request is put into the purgatory, it will have a held reference and hence cannot be garbage collected;</span><br>     <span class="hljs-comment">// hence we clear its data here in order to let GC reclaim its memory since it is already appended to log</span><br>     produceRequest.clearPartitionRecords()<br>   &#125;<br> &#125;<br></code></pre></td></tr></table></figure>

<h3 id="ReplicaManager-appendRecords"><a href="#ReplicaManager-appendRecords" class="headerlink" title="ReplicaManager#appendRecords()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@f5f8ff0d24ce9f564fe1d7225db7121f22d1b296/-/blob/core/src/main/scala/kafka/server/ReplicaManager.scala?L581">ReplicaManager#appendRecords()</a></h3><ol>
<li>KafkaApis.handle() 调用 ReplicaManager#appendRecords() 触发消息复制</li>
<li>ReplicaManager 消息复制 action 放到 <a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/server/ReplicaFetcherManager.scala">ReplicaFetcherManager</a></li>
<li>KafkaApis 在 finally 块中 ReplicaManager#tryCompleteActions() 将消息写到本地 log</li>
<li>其它 Broker 通过 <a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala">ReplicaFetcherThread</a> 线程从 leader partition broker 顺序同步 log，实现消息复制</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ReplicaManager</span>(<span class="hljs-params">...</span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">Logging</span> <span class="hljs-keyword">with</span> <span class="hljs-title">KafkaMetricsGroup</span> </span>&#123;<br>	<span class="hljs-comment">// ReplicateFetcherManager put replica actions and executed by ReplicaFetcherThread</span><br>	<span class="hljs-keyword">val</span> replicaFetcherManager = createReplicaFetcherManager(metrics, time, threadNamePrefix, quotaManagers.follower)<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Append messages to leader replicas of the partition, and wait for them to be replicated to other replicas;</span><br><span class="hljs-comment">   * the callback function will be triggered either when timeout or the required acks are satisfied;</span><br><span class="hljs-comment">   * if the callback function itself is already synchronized on some object then pass this object to avoid deadlock.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * Noted that all pending delayed check operations are stored in a queue. All callers to ReplicaManager.appendRecords()</span><br><span class="hljs-comment">   * are expected to call ActionQueue.tryCompleteActions for all affected partitions, without holding any conflicting</span><br><span class="hljs-comment">   * locks.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">appendRecords</span></span>(timeout: <span class="hljs-type">Long</span>,<br>                    requiredAcks: <span class="hljs-type">Short</span>,<br>                    internalTopicsAllowed: <span class="hljs-type">Boolean</span>,<br>                    origin: <span class="hljs-type">AppendOrigin</span>,<br>                    entriesPerPartition: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">MemoryRecords</span>],<br>                    responseCallback: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">PartitionResponse</span>] =&gt; <span class="hljs-type">Unit</span>,<br>                    delayedProduceLock: <span class="hljs-type">Option</span>[<span class="hljs-type">Lock</span>] = <span class="hljs-type">None</span>,<br>                    recordConversionStatsCallback: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">RecordConversionStats</span>] =&gt; <span class="hljs-type">Unit</span> = _ =&gt; (),<br>                    requestLocal: <span class="hljs-type">RequestLocal</span> = <span class="hljs-type">RequestLocal</span>.<span class="hljs-type">NoCaching</span>): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123;<br>      <span class="hljs-keyword">val</span> sTime = time.milliseconds<br>      <span class="hljs-keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,<br>        origin, entriesPerPartition, requiredAcks, requestLocal)<br>      debug(<span class="hljs-string">&quot;Produce to local log in %d ms&quot;</span>.format(time.milliseconds - sTime))<br><br>      <span class="hljs-keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="hljs-keyword">case</span> (topicPartition, result) =&gt;<br>        topicPartition -&gt; <span class="hljs-type">ProducePartitionStatus</span>(<br>          result.info.lastOffset + <span class="hljs-number">1</span>, <span class="hljs-comment">// required offset</span><br>          <span class="hljs-keyword">new</span> <span class="hljs-type">PartitionResponse</span>(<br>            result.error,<br>            result.info.firstOffset.map(_.messageOffset).getOrElse(<span class="hljs-number">-1</span>),<br>            result.info.logAppendTime,<br>            result.info.logStartOffset,<br>            result.info.recordErrors.asJava,<br>            result.info.errorMessage<br>          )<br>        ) <span class="hljs-comment">// response status</span><br>      &#125;<br><br>      actionQueue.add &#123;<br>        () =&gt;<br>          localProduceResults.foreach &#123;<br>            <span class="hljs-keyword">case</span> (topicPartition, result) =&gt;<br>              <span class="hljs-keyword">val</span> requestKey = <span class="hljs-type">TopicPartitionOperationKey</span>(topicPartition)<br>              result.info.leaderHwChange <span class="hljs-keyword">match</span> &#123;<br>                <span class="hljs-keyword">case</span> <span class="hljs-type">LeaderHwChange</span>.<span class="hljs-type">Increased</span> =&gt;<br>                  <span class="hljs-comment">// some delayed operations may be unblocked after HW changed</span><br>                  delayedProducePurgatory.checkAndComplete(requestKey)<br>                  delayedFetchPurgatory.checkAndComplete(requestKey)<br>                  delayedDeleteRecordsPurgatory.checkAndComplete(requestKey)<br>                <span class="hljs-keyword">case</span> <span class="hljs-type">LeaderHwChange</span>.<span class="hljs-type">Same</span> =&gt;<br>                  <span class="hljs-comment">// probably unblock some follower fetch requests since log end offset has been updated</span><br>                  delayedFetchPurgatory.checkAndComplete(requestKey)<br>                <span class="hljs-keyword">case</span> <span class="hljs-type">LeaderHwChange</span>.<span class="hljs-type">None</span> =&gt;<br>                  <span class="hljs-comment">// nothing</span><br>              &#125;<br>          &#125;<br>      &#125;<br><br>      recordConversionStatsCallback(localProduceResults.map &#123; <span class="hljs-keyword">case</span> (k, v) =&gt; k -&gt; v.info.recordConversionStats &#125;)<br><br>      <span class="hljs-keyword">if</span> (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;<br>        <span class="hljs-comment">// create delayed produce operation</span><br>        <span class="hljs-keyword">val</span> produceMetadata = <span class="hljs-type">ProduceMetadata</span>(requiredAcks, produceStatus)<br>        <span class="hljs-keyword">val</span> delayedProduce = <span class="hljs-keyword">new</span> <span class="hljs-type">DelayedProduce</span>(timeout, produceMetadata, <span class="hljs-keyword">this</span>, responseCallback, delayedProduceLock)<br><br>        <span class="hljs-comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span><br>        <span class="hljs-keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="hljs-type">TopicPartitionOperationKey</span>(_)).toSeq<br><br>        <span class="hljs-comment">// try to complete the request immediately, otherwise put it into the purgatory</span><br>        <span class="hljs-comment">// this is because while the delayed produce operation is being created, new</span><br>        <span class="hljs-comment">// requests may arrive and hence make this operation completable.</span><br>        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)<br><br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// we can respond immediately</span><br>        <span class="hljs-keyword">val</span> produceResponseStatus = produceStatus.map &#123; <span class="hljs-keyword">case</span> (k, status) =&gt; k -&gt; status.responseStatus &#125;<br>        responseCallback(produceResponseStatus)<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// If required.acks is outside accepted range, something is wrong with the client</span><br>      <span class="hljs-comment">// Just return an error and don&#x27;t handle the request at all</span><br>      <span class="hljs-keyword">val</span> responseStatus = entriesPerPartition.map &#123; <span class="hljs-keyword">case</span> (topicPartition, _) =&gt;<br>        topicPartition -&gt; <span class="hljs-keyword">new</span> <span class="hljs-type">PartitionResponse</span>(<br>          <span class="hljs-type">Errors</span>.<span class="hljs-type">INVALID_REQUIRED_ACKS</span>,<br>          <span class="hljs-type">LogAppendInfo</span>.<span class="hljs-type">UnknownLogAppendInfo</span>.firstOffset.map(_.messageOffset).getOrElse(<span class="hljs-number">-1</span>),<br>          <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">NO_TIMESTAMP</span>,<br>          <span class="hljs-type">LogAppendInfo</span>.<span class="hljs-type">UnknownLogAppendInfo</span>.logStartOffset<br>        )<br>      &#125;<br>      responseCallback(responseStatus)<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Append the messages to the local replica logs</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">appendToLocalLog</span></span>(internalTopicsAllowed: <span class="hljs-type">Boolean</span>,<br>                               origin: <span class="hljs-type">AppendOrigin</span>,<br>                               entriesPerPartition: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">MemoryRecords</span>],<br>                               requiredAcks: <span class="hljs-type">Short</span>,<br>                               requestLocal: <span class="hljs-type">RequestLocal</span>): <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">LogAppendResult</span>] = &#123;<br>    <span class="hljs-keyword">val</span> traceEnabled = isTraceEnabled<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processFailedRecord</span></span>(topicPartition: <span class="hljs-type">TopicPartition</span>, t: <span class="hljs-type">Throwable</span>) = &#123;<br>      <span class="hljs-keyword">val</span> logStartOffset = onlinePartition(topicPartition).map(_.logStartOffset).getOrElse(<span class="hljs-number">-1</span>L)<br>      brokerTopicStats.topicStats(topicPartition.topic).failedProduceRequestRate.mark()<br>      brokerTopicStats.allTopicsStats.failedProduceRequestRate.mark()<br>      error(<span class="hljs-string">s&quot;Error processing append operation on partition <span class="hljs-subst">$topicPartition</span>&quot;</span>, t)<br><br>      logStartOffset<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (traceEnabled)<br>      trace(<span class="hljs-string">s&quot;Append [<span class="hljs-subst">$entriesPerPartition</span>] to local log&quot;</span>)<br><br>    entriesPerPartition.map &#123; <span class="hljs-keyword">case</span> (topicPartition, records) =&gt;<br>      brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark()<br>      brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()<br><br>      <span class="hljs-comment">// reject appending to internal topics if it is not allowed</span><br>      <span class="hljs-keyword">if</span> (<span class="hljs-type">Topic</span>.isInternal(topicPartition.topic) &amp;&amp; !internalTopicsAllowed) &#123;<br>        (topicPartition, <span class="hljs-type">LogAppendResult</span>(<br>          <span class="hljs-type">LogAppendInfo</span>.<span class="hljs-type">UnknownLogAppendInfo</span>,<br>          <span class="hljs-type">Some</span>(<span class="hljs-keyword">new</span> <span class="hljs-type">InvalidTopicException</span>(<span class="hljs-string">s&quot;Cannot append to internal topic <span class="hljs-subst">$&#123;topicPartition.topic&#125;</span>&quot;</span>))))<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>          <span class="hljs-keyword">val</span> partition = getPartitionOrException(topicPartition)<br>          <span class="hljs-keyword">val</span> info = partition.appendRecordsToLeader(records, origin, requiredAcks, requestLocal)<br>          <span class="hljs-keyword">val</span> numAppendedMessages = info.numMessages<br><br>          <span class="hljs-comment">// update stats for successfully appended bytes and messages as bytesInRate and messageInRate</span><br>          brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)<br>          brokerTopicStats.allTopicsStats.bytesInRate.mark(records.sizeInBytes)<br>          brokerTopicStats.topicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages)<br>          brokerTopicStats.allTopicsStats.messagesInRate.mark(numAppendedMessages)<br><br>          <span class="hljs-keyword">if</span> (traceEnabled)<br>            trace(<span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;records.sizeInBytes&#125;</span> written to log <span class="hljs-subst">$topicPartition</span> beginning at offset &quot;</span> +<br>              <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;info.firstOffset.getOrElse(-1)&#125;</span> and ending at offset <span class="hljs-subst">$&#123;info.lastOffset&#125;</span>&quot;</span>)<br><br>          (topicPartition, <span class="hljs-type">LogAppendResult</span>(info))<br>        &#125; <span class="hljs-keyword">catch</span> &#123;<br>          <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> Failed produce requests metric is not incremented for known exceptions</span><br>          <span class="hljs-comment">// it is supposed to indicate un-expected failures of a broker in handling a produce request</span><br>          <span class="hljs-keyword">case</span> e@ (_: <span class="hljs-type">UnknownTopicOrPartitionException</span> |<br>                   _: <span class="hljs-type">NotLeaderOrFollowerException</span> |<br>                   _: <span class="hljs-type">RecordTooLargeException</span> |<br>                   _: <span class="hljs-type">RecordBatchTooLargeException</span> |<br>                   _: <span class="hljs-type">CorruptRecordException</span> |<br>                   _: <span class="hljs-type">KafkaStorageException</span>) =&gt;<br>            (topicPartition, <span class="hljs-type">LogAppendResult</span>(<span class="hljs-type">LogAppendInfo</span>.<span class="hljs-type">UnknownLogAppendInfo</span>, <span class="hljs-type">Some</span>(e)))<br>          <span class="hljs-keyword">case</span> rve: <span class="hljs-type">RecordValidationException</span> =&gt;<br>            <span class="hljs-keyword">val</span> logStartOffset = processFailedRecord(topicPartition, rve.invalidException)<br>            <span class="hljs-keyword">val</span> recordErrors = rve.recordErrors<br>            (topicPartition, <span class="hljs-type">LogAppendResult</span>(<span class="hljs-type">LogAppendInfo</span>.unknownLogAppendInfoWithAdditionalInfo(<br>              logStartOffset, recordErrors, rve.invalidException.getMessage), <span class="hljs-type">Some</span>(rve.invalidException)))<br>          <span class="hljs-keyword">case</span> t: <span class="hljs-type">Throwable</span> =&gt;<br>            <span class="hljs-keyword">val</span> logStartOffset = processFailedRecord(topicPartition, t)<br>            (topicPartition, <span class="hljs-type">LogAppendResult</span>(<span class="hljs-type">LogAppendInfo</span>.unknownLogAppendInfoWithLogStartOffset(logStartOffset), <span class="hljs-type">Some</span>(t)))<br>        &#125;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="ReplicaFetcherManager"><a href="#ReplicaFetcherManager" class="headerlink" title="ReplicaFetcherManager"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@f5f8ff0d24ce9f564fe1d7225db7121f22d1b296/-/blob/core/src/main/scala/kafka/server/ReplicaFetcherManager.scala">ReplicaFetcherManager</a></h3><ol>
<li>ReplicaFetcherManager 持有 ReplicaManager 对象，是在 ReplicaManager 构造 ReplicaFetcherManager 时将自身传入的</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// construction parameter including ReplicaManager</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ReplicaFetcherManager</span>(<span class="hljs-params">brokerConfig: <span class="hljs-type">KafkaConfig</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            protected val replicaManager: <span class="hljs-type">ReplicaManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            metrics: <span class="hljs-type">Metrics</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            time: <span class="hljs-type">Time</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            threadNamePrefix: <span class="hljs-type">Option</span>[<span class="hljs-type">String</span>] = <span class="hljs-type">None</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            quotaManager: <span class="hljs-type">ReplicationQuotaManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                            metadataVersionSupplier: (</span>) <span class="hljs-title">=&gt;</span> <span class="hljs-title">MetadataVersion</span>)</span><br>      <span class="hljs-keyword">extends</span> <span class="hljs-type">AbstractFetcherManager</span>[<span class="hljs-type">ReplicaFetcherThread</span>](<br>        name = <span class="hljs-string">&quot;ReplicaFetcherManager on broker &quot;</span> + brokerConfig.brokerId,<br>        clientId = <span class="hljs-string">&quot;Replica&quot;</span>,<br>        numFetchers = brokerConfig.numReplicaFetchers) &#123;<br><br>  <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createFetcherThread</span></span>(fetcherId: <span class="hljs-type">Int</span>, sourceBroker: <span class="hljs-type">BrokerEndPoint</span>): <span class="hljs-type">ReplicaFetcherThread</span> = &#123;<br>    <span class="hljs-keyword">val</span> prefix = threadNamePrefix.map(tp =&gt; <span class="hljs-string">s&quot;<span class="hljs-subst">$tp</span>:&quot;</span>).getOrElse(<span class="hljs-string">&quot;&quot;</span>)<br>    <span class="hljs-keyword">val</span> threadName = <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;prefix&#125;</span>ReplicaFetcherThread-<span class="hljs-subst">$fetcherId</span>-<span class="hljs-subst">$&#123;sourceBroker.id&#125;</span>&quot;</span><br>    <span class="hljs-keyword">val</span> logContext = <span class="hljs-keyword">new</span> <span class="hljs-type">LogContext</span>(<span class="hljs-string">s&quot;[ReplicaFetcher replicaId=<span class="hljs-subst">$&#123;brokerConfig.brokerId&#125;</span>, leaderId=<span class="hljs-subst">$&#123;sourceBroker.id&#125;</span>, &quot;</span> +<br>      <span class="hljs-string">s&quot;fetcherId=<span class="hljs-subst">$fetcherId</span>] &quot;</span>)<br>    <span class="hljs-keyword">val</span> endpoint = <span class="hljs-keyword">new</span> <span class="hljs-type">BrokerBlockingSender</span>(sourceBroker, brokerConfig, metrics, time, fetcherId,<br>      <span class="hljs-string">s&quot;broker-<span class="hljs-subst">$&#123;brokerConfig.brokerId&#125;</span>-fetcher-<span class="hljs-subst">$fetcherId</span>&quot;</span>, logContext)<br>    <span class="hljs-keyword">val</span> fetchSessionHandler = <span class="hljs-keyword">new</span> <span class="hljs-type">FetchSessionHandler</span>(logContext, sourceBroker.id)<br>    <span class="hljs-keyword">val</span> leader = <span class="hljs-keyword">new</span> <span class="hljs-type">RemoteLeaderEndPoint</span>(logContext.logPrefix, endpoint, fetchSessionHandler, brokerConfig,<br>      replicaManager, quotaManager, metadataVersionSupplier)<br>		<span class="hljs-comment">// passing ReplicaManager to ReplicaFetcherThread</span><br>    <span class="hljs-keyword">new</span> <span class="hljs-type">ReplicaFetcherThread</span>(threadName, leader, brokerConfig, failedPartitions, replicaManager,<br>      quotaManager, logContext.logPrefix, metadataVersionSupplier)<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shutdown</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    info(<span class="hljs-string">&quot;shutting down&quot;</span>)<br>    closeAllFetchers()<br>    info(<span class="hljs-string">&quot;shutdown completed&quot;</span>)<br>  &#125;<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ReplicaFetcherThread</span>(<span class="hljs-params">name: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           leader: <span class="hljs-type">LeaderEndPoint</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           brokerConfig: <span class="hljs-type">KafkaConfig</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           failedPartitions: <span class="hljs-type">FailedPartitions</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           replicaMgr: <span class="hljs-type">ReplicaManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           quota: <span class="hljs-type">ReplicaQuota</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           logPrefix: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           metadataVersionSupplier: (</span>) <span class="hljs-title">=&gt;</span> <span class="hljs-title">MetadataVersion</span>)</span><br>  <span class="hljs-keyword">extends</span> <span class="hljs-type">AbstractFetcherThread</span>(name = name,<br>                                clientId = name,<br>                                leader = leader,<br>                                failedPartitions,<br>                                fetchBackOffMs = brokerConfig.replicaFetchBackoffMs,<br>                                isInterruptible = <span class="hljs-literal">false</span>,<br>                                replicaMgr.brokerTopicStats) &#123;<br>	<span class="hljs-comment">// from AbstractFetcherThread, invoked by run</span><br>	<span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">doWork</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    maybeTruncate()<br>    maybeFetch()<br>  &#125;<br><br>	<span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maybeFetch</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> fetchRequestOpt = inLock(partitionMapLock) &#123;<br>      <span class="hljs-keyword">val</span> <span class="hljs-type">ResultWithPartitions</span>(fetchRequestOpt, partitionsWithError) = leader.buildFetch(partitionStates.partitionStateMap.asScala)<br><br>      handlePartitionsWithErrors(partitionsWithError, <span class="hljs-string">&quot;maybeFetch&quot;</span>)<br><br>      <span class="hljs-keyword">if</span> (fetchRequestOpt.isEmpty) &#123;<br>        trace(<span class="hljs-string">s&quot;There are no active partitions. Back off for <span class="hljs-subst">$fetchBackOffMs</span> ms before sending a fetch request&quot;</span>)<br>        partitionMapCond.await(fetchBackOffMs, <span class="hljs-type">TimeUnit</span>.<span class="hljs-type">MILLISECONDS</span>)<br>      &#125;<br><br>      fetchRequestOpt<br>    &#125;<br><br>    fetchRequestOpt.foreach &#123; <span class="hljs-keyword">case</span> <span class="hljs-type">ReplicaFetch</span>(sessionPartitions, fetchRequest) =&gt;<br>      processFetchRequest(sessionPartitions, fetchRequest)<br>    &#125;<br>  &#125;<br><br>	<span class="hljs-comment">// process fetched data</span><br>  <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processPartitionData</span></span>(topicPartition: <span class="hljs-type">TopicPartition</span>,<br>                                    fetchOffset: <span class="hljs-type">Long</span>,<br>                                    partitionData: <span class="hljs-type">FetchData</span>): <span class="hljs-type">Option</span>[<span class="hljs-type">LogAppendInfo</span>] = &#123;<br>    <span class="hljs-keyword">val</span> logTrace = isTraceEnabled<br>    <span class="hljs-keyword">val</span> partition = replicaMgr.getPartitionOrException(topicPartition)<br>    <span class="hljs-keyword">val</span> log = partition.localLogOrException<br>    <span class="hljs-keyword">val</span> records = toMemoryRecords(<span class="hljs-type">FetchResponse</span>.recordsOrFail(partitionData))<br><br>    maybeWarnIfOversizedRecords(records, topicPartition)<br><br>    <span class="hljs-keyword">if</span> (fetchOffset != log.logEndOffset)<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">&quot;Offset mismatch for partition %s: fetched offset = %d, log end offset = %d.&quot;</span>.format(<br>        topicPartition, fetchOffset, log.logEndOffset))<br><br>    <span class="hljs-keyword">if</span> (logTrace)<br>      trace(<span class="hljs-string">&quot;Follower has replica log end offset %d for partition %s. Received %d messages and leader hw %d&quot;</span><br>        .format(log.logEndOffset, topicPartition, records.sizeInBytes, partitionData.highWatermark))<br><br>    <span class="hljs-comment">// Append the leader&#x27;s messages to the log</span><br>    <span class="hljs-keyword">val</span> logAppendInfo = partition.appendRecordsToFollowerOrFutureReplica(records, isFuture = <span class="hljs-literal">false</span>)<br><br>    <span class="hljs-keyword">if</span> (logTrace)<br>      trace(<span class="hljs-string">&quot;Follower has replica log end offset %d after appending %d bytes of messages for partition %s&quot;</span><br>        .format(log.logEndOffset, records.sizeInBytes, topicPartition))<br>    <span class="hljs-keyword">val</span> leaderLogStartOffset = partitionData.logStartOffset<br><br>    <span class="hljs-comment">// For the follower replica, we do not need to keep its segment base offset and physical position.</span><br>    <span class="hljs-comment">// These values will be computed upon becoming leader or handling a preferred read replica fetch.</span><br>    <span class="hljs-keyword">val</span> followerHighWatermark = log.updateHighWatermark(partitionData.highWatermark)<br>    log.maybeIncrementLogStartOffset(leaderLogStartOffset, <span class="hljs-type">LeaderOffsetIncremented</span>)<br>    <span class="hljs-keyword">if</span> (logTrace)<br>      trace(<span class="hljs-string">s&quot;Follower set replica high watermark for partition <span class="hljs-subst">$topicPartition</span> to <span class="hljs-subst">$followerHighWatermark</span>&quot;</span>)<br><br>    <span class="hljs-comment">// Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication</span><br>    <span class="hljs-comment">// traffic doesn&#x27;t exceed quota.</span><br>    <span class="hljs-keyword">if</span> (quota.isThrottled(topicPartition))<br>      quota.record(records.sizeInBytes)<br><br>    <span class="hljs-keyword">if</span> (partition.isReassigning &amp;&amp; partition.isAddingLocalReplica)<br>      brokerTopicStats.updateReassignmentBytesIn(records.sizeInBytes)<br><br>    brokerTopicStats.updateReplicationBytesIn(records.sizeInBytes)<br><br>    logAppendInfo<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="RemoteLeaderEndPoint-fetch"><a href="#RemoteLeaderEndPoint-fetch" class="headerlink" title="RemoteLeaderEndPoint#fetch()"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/server/RemoteLeaderEndPoint.scala?L53:7">RemoteLeaderEndPoint#fetch()</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Facilitates fetches from a remote replica leader.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @param logPrefix The log prefix</span><br><span class="hljs-comment"> * @param blockingSender The raw leader endpoint used to communicate with the leader</span><br><span class="hljs-comment"> * @param fetchSessionHandler A FetchSessionHandler to track the partitions in the session</span><br><span class="hljs-comment"> * @param brokerConfig Broker configuration</span><br><span class="hljs-comment"> * @param replicaManager A ReplicaManager</span><br><span class="hljs-comment"> * @param quota The quota, used when building a fetch request</span><br><span class="hljs-comment"> * @param metadataVersionSupplier A supplier that returns the current MetadataVersion. This can change during</span><br><span class="hljs-comment"> *                                runtime in KRaft mode.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RemoteLeaderEndPoint</span>(<span class="hljs-params">logPrefix: <span class="hljs-type">String</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           blockingSender: <span class="hljs-type">BlockingSend</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           private[server] val fetchSessionHandler: <span class="hljs-type">FetchSessionHandler</span>, // visible for testing</span></span><br><span class="hljs-params"><span class="hljs-class">                           brokerConfig: <span class="hljs-type">KafkaConfig</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           replicaManager: <span class="hljs-type">ReplicaManager</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           quota: <span class="hljs-type">ReplicaQuota</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                           metadataVersionSupplier: (</span>) <span class="hljs-title">=&gt;</span> <span class="hljs-title">MetadataVersion</span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">LeaderEndPoint</span> <span class="hljs-keyword">with</span> <span class="hljs-title">Logging</span> </span>&#123;<br>	<span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fetch</span></span>(fetchRequest: <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">Builder</span>): collection.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">FetchData</span>] = &#123;<br>    <span class="hljs-keyword">val</span> clientResponse = <span class="hljs-keyword">try</span> &#123;<br>      blockingSender.sendRequest(fetchRequest)<br>    &#125; <span class="hljs-keyword">catch</span> &#123;<br>      <span class="hljs-keyword">case</span> t: <span class="hljs-type">Throwable</span> =&gt;<br>        fetchSessionHandler.handleError(t)<br>        <span class="hljs-keyword">throw</span> t<br>    &#125;<br>    <span class="hljs-keyword">val</span> fetchResponse = clientResponse.responseBody.asInstanceOf[<span class="hljs-type">FetchResponse</span>]<br>    <span class="hljs-keyword">if</span> (!fetchSessionHandler.handleResponse(fetchResponse, clientResponse.requestHeader().apiVersion())) &#123;<br>      <span class="hljs-comment">// If we had a session topic ID related error, throw it, otherwise return an empty fetch data map.</span><br>      <span class="hljs-keyword">if</span> (fetchResponse.error == <span class="hljs-type">Errors</span>.<span class="hljs-type">FETCH_SESSION_TOPIC_ID_ERROR</span>) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-type">Errors</span>.forCode(fetchResponse.error().code()).exception()<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-type">Map</span>.empty<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      fetchResponse.responseData(fetchSessionHandler.sessionTopicNames, clientResponse.requestHeader().apiVersion()).asScala<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="LogManager"><a href="#LogManager" class="headerlink" title="LogManager"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/log/LogManager.scala">LogManager</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * The entry point to the kafka log management subsystem. The log manager is responsible for log creation, retrieval, and cleaning.</span><br><span class="hljs-comment"> * All read and write operations are delegated to the individual log instances.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The log manager maintains logs in one or more directories. New logs are created in the data directory</span><br><span class="hljs-comment"> * with the fewest logs. No attempt is made to move partitions after the fact or balance based on</span><br><span class="hljs-comment"> * size or I/O rate.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * A background thread handles log retention by periodically truncating excess log segments.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@threadsafe</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LogManager</span>(<span class="hljs-params">...</span>) </span>&#123; <br>	<span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="OffsetIndex"><a href="#OffsetIndex" class="headerlink" title="OffsetIndex"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/log/OffsetIndex.scala?L53">OffsetIndex</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * An index that maps offsets to physical file locations for a particular log segment. This index may be sparse:</span><br><span class="hljs-comment"> * that is it may not hold an entry for all messages in the log.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The index is stored in a file that is pre-allocated to hold a fixed maximum number of 8-byte entries.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The index supports lookups against a memory-map of this file. These lookups are done using a simple binary search variant</span><br><span class="hljs-comment"> * to locate the offset/location pair for the greatest offset less than or equal to the target offset.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Index files can be opened in two ways: either as an empty, mutable index that allows appends or</span><br><span class="hljs-comment"> * an immutable read-only index file that has previously been populated. The makeReadOnly method will turn a mutable file into an</span><br><span class="hljs-comment"> * immutable one and truncate off any extra bytes. This is done when the index file is rolled over.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * No attempt is made to checksum the contents of this file, in the event of a crash it is rebuilt.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The file format is a series of entries. The physical format is a 4 byte &quot;relative&quot; offset and a 4 byte file location for the</span><br><span class="hljs-comment"> * message with that offset. The offset stored is relative to the base offset of the index file. So, for example,</span><br><span class="hljs-comment"> * if the base offset was 50, then the offset 55 would be stored as 5. Using relative offsets in this way let&#x27;s us use</span><br><span class="hljs-comment"> * only 4 bytes for the offset.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The frequency of entries is up to the user of this class.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * All external APIs translate from relative offsets to full offsets, so users of this class do not interact with the internal</span><br><span class="hljs-comment"> * storage format.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-comment">// Avoid shadowing mutable `file` in AbstractIndex</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">OffsetIndex</span>(<span class="hljs-params">...</span>) </span>&#123;<br>	<span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="ZkConfigManager"><a href="#ZkConfigManager" class="headerlink" title="ZkConfigManager"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/core/src/main/scala/kafka/server/ZkConfigManager.scala?L86">ZkConfigManager</a></h3><p>负现动态监控 ZooKeeper 上的配置变化</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * This class initiates and carries out config changes for all entities defined in ConfigType.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * It works as follows.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Config is stored under the path: /config/entityType/entityName</span><br><span class="hljs-comment"> *   E.g. /config/topics/&lt;topic_name&gt; and /config/clients/&lt;clientId&gt;</span><br><span class="hljs-comment"> * This znode stores the overrides for this entity in properties format with defaults stored using entityName &quot;&lt;default&gt;&quot;.</span><br><span class="hljs-comment"> * Multiple entity names may be specified (eg. &lt;user, client-id&gt; quotas) using a hierarchical path:</span><br><span class="hljs-comment"> *   E.g. /config/users/&lt;user&gt;/clients/&lt;clientId&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * To avoid watching all topics for changes instead we have a notification path</span><br><span class="hljs-comment"> *   /config/changes</span><br><span class="hljs-comment"> * The ZkConfigManager has a child watch on this path.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * To update a config we first update the config properties. Then we create a new sequential</span><br><span class="hljs-comment"> * znode under the change path which contains the name of the entityType and entityName that was updated, say</span><br><span class="hljs-comment"> *   /config/changes/config_change_13321</span><br><span class="hljs-comment"> * The sequential znode contains data in this format: &#123;&quot;version&quot; : 1, &quot;entity_type&quot;:&quot;topic/client&quot;, &quot;entity_name&quot; : &quot;topic_name/client_id&quot;&#125;</span><br><span class="hljs-comment"> * This is just a notification--the actual config change is stored only once under the /config/entityType/entityName path.</span><br><span class="hljs-comment"> * Version 2 of notifications has the format: &#123;&quot;version&quot; : 2, &quot;entity_path&quot;:&quot;entity_type/entity_name&quot;&#125;</span><br><span class="hljs-comment"> * Multiple entities may be specified as a hierarchical path (eg. users/&lt;user&gt;/clients/&lt;clientId&gt;).</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This will fire a watcher on all brokers. This watcher works as follows. It reads all the config change notifications.</span><br><span class="hljs-comment"> * It keeps track of the highest config change suffix number it has applied previously. For any previously applied change it finds</span><br><span class="hljs-comment"> * it checks if this notification is larger than a static expiration time (say 10mins) and if so it deletes this notification.</span><br><span class="hljs-comment"> * For any new changes it reads the new configuration, combines it with the defaults, and updates the existing config.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Note that config is always read from the config path in zk, the notification is just a trigger to do so. So if a broker is</span><br><span class="hljs-comment"> * down and misses a change that is fine--when it restarts it will be loading the full config anyway. Note also that</span><br><span class="hljs-comment"> * if there are two consecutive config changes it is possible that only the last one will be applied (since by the time the</span><br><span class="hljs-comment"> * broker reads the config the both changes may have been made). In this case the broker would needlessly refresh the config twice,</span><br><span class="hljs-comment"> * but that is harmless.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * On restart the config manager re-processes all notifications. This will usually be wasted work, but avoids any race conditions</span><br><span class="hljs-comment"> * on startup where a change might be missed between the initial config load and registering for change notifications.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ZkConfigManager</span>(<span class="hljs-params">...</span>) </span>&#123;<br>  <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java?L86">Consumer</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * A client that consumes records from a Kafka cluster.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * This client transparently handles the failure of Kafka brokers, and transparently adapts as topic partitions</span><br><span class="hljs-comment"> * it fetches migrate within the cluster. This client also interacts with the broker to allow groups of</span><br><span class="hljs-comment"> * consumers to load balance consumption using &lt;a href=&quot;#consumergroups&quot;&gt;consumer groups&lt;/a&gt;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The consumer maintains TCP connections to the necessary brokers to fetch data.</span><br><span class="hljs-comment"> * Failure to close the consumer after use will leak these connections.</span><br><span class="hljs-comment"> * The consumer is not thread-safe. See &lt;a href=&quot;#multithreaded&quot;&gt;Multi-threaded Processing&lt;/a&gt; for more details.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;Cross-Version Compatibility&lt;/h3&gt;</span><br><span class="hljs-comment"> * This client can communicate with brokers that are version 0.10.0 or newer. Older or newer brokers may not support</span><br><span class="hljs-comment"> * certain features. For example, 0.10.0 brokers do not support offsetsForTimes, because this feature was added</span><br><span class="hljs-comment"> * in version 0.10.1. You will receive an &#123;@link org.apache.kafka.common.errors.UnsupportedVersionException&#125;</span><br><span class="hljs-comment"> * when invoking an API that is not available on the running broker version.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;Offsets and Consumer Position&lt;/h3&gt;</span><br><span class="hljs-comment"> * Kafka maintains a numerical offset for each record in a partition. This offset acts as a unique identifier of</span><br><span class="hljs-comment"> * a record within that partition, and also denotes the position of the consumer in the partition. For example, a consumer</span><br><span class="hljs-comment"> * which is at position 5 has consumed records with offsets 0 through 4 and will next receive the record with offset 5. There</span><br><span class="hljs-comment"> * are actually two notions of position relevant to the user of the consumer:</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &#123;@link #position(TopicPartition) position&#125; of the consumer gives the offset of the next record that will be given</span><br><span class="hljs-comment"> * out. It will be one larger than the highest offset the consumer has seen in that partition. It automatically advances</span><br><span class="hljs-comment"> * every time the consumer receives messages in a call to &#123;@link #poll(Duration)&#125;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &#123;@link #commitSync() committed position&#125; is the last offset that has been stored securely. Should the</span><br><span class="hljs-comment"> * process fail and restart, this is the offset that the consumer will recover to. The consumer can either automatically commit</span><br><span class="hljs-comment"> * offsets periodically; or it can choose to control this committed position manually by calling one of the commit APIs</span><br><span class="hljs-comment"> * (e.g. &#123;@link #commitSync() commitSync&#125; and &#123;@link #commitAsync(OffsetCommitCallback) commitAsync&#125;).</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * This distinction gives the consumer control over when a record is considered consumed. It is discussed in further</span><br><span class="hljs-comment"> * detail below.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;&lt;a name=&quot;consumergroups&quot;&gt;Consumer Groups and Topic Subscriptions&lt;/a&gt;&lt;/h3&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Kafka uses the concept of &lt;i&gt;consumer groups&lt;/i&gt; to allow a pool of processes to divide the work of consuming and</span><br><span class="hljs-comment"> * processing records. These processes can either be running on the same machine or they can be</span><br><span class="hljs-comment"> * distributed over many machines to provide scalability and fault tolerance for processing. All consumer instances</span><br><span class="hljs-comment"> * sharing the same &#123;@code group.id&#125; will be part of the same consumer group.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Each consumer in a group can dynamically set the list of topics it wants to subscribe to through one of the</span><br><span class="hljs-comment"> * &#123;@link #subscribe(Collection, ConsumerRebalanceListener) subscribe&#125; APIs. Kafka will deliver each message in the</span><br><span class="hljs-comment"> * subscribed topics to one process in each consumer group. This is achieved by balancing the partitions between all</span><br><span class="hljs-comment"> * members in the consumer group so that each partition is assigned to exactly one consumer in the group. So if there</span><br><span class="hljs-comment"> * is a topic with four partitions, and a consumer group with two processes, each process would consume from two partitions.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Membership in a consumer group is maintained dynamically: if a process fails, the partitions assigned to it will</span><br><span class="hljs-comment"> * be reassigned to other consumers in the same group. Similarly, if a new consumer joins the group, partitions will be moved</span><br><span class="hljs-comment"> * from existing consumers to the new one. This is known as &lt;i&gt;rebalancing&lt;/i&gt; the group and is discussed in more</span><br><span class="hljs-comment"> * detail &lt;a href=&quot;#failuredetection&quot;&gt;below&lt;/a&gt;. Group rebalancing is also used when new partitions are added</span><br><span class="hljs-comment"> * to one of the subscribed topics or when a new topic matching a &#123;@link #subscribe(Pattern, ConsumerRebalanceListener) subscribed regex&#125;</span><br><span class="hljs-comment"> * is created. The group will automatically detect the new partitions through periodic metadata refreshes and</span><br><span class="hljs-comment"> * assign them to members of the group.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Conceptually you can think of a consumer group as being a single logical subscriber that happens to be made up of</span><br><span class="hljs-comment"> * multiple processes. As a multi-subscriber system, Kafka naturally supports having any number of consumer groups for a</span><br><span class="hljs-comment"> * given topic without duplicating data (additional consumers are actually quite cheap).</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * This is a slight generalization of the functionality that is common in messaging systems. To get semantics similar to</span><br><span class="hljs-comment"> * a queue in a traditional messaging system all processes would be part of a single consumer group and hence record</span><br><span class="hljs-comment"> * delivery would be balanced over the group like with a queue. Unlike a traditional messaging system, though, you can</span><br><span class="hljs-comment"> * have multiple such groups. To get semantics similar to pub-sub in a traditional messaging system each process would</span><br><span class="hljs-comment"> * have its own consumer group, so each process would subscribe to all the records published to the topic.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * In addition, when group reassignment happens automatically, consumers can be notified through a &#123;@link ConsumerRebalanceListener&#125;,</span><br><span class="hljs-comment"> * which allows them to finish necessary application-level logic such as state cleanup, manual offset</span><br><span class="hljs-comment"> * commits, etc. See &lt;a href=&quot;#rebalancecallback&quot;&gt;Storing Offsets Outside Kafka&lt;/a&gt; for more details.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * It is also possible for the consumer to &lt;a href=&quot;#manualassignment&quot;&gt;manually assign&lt;/a&gt; specific partitions</span><br><span class="hljs-comment"> * (similar to the older &quot;simple&quot; consumer) using &#123;@link #assign(Collection)&#125;. In this case, dynamic partition</span><br><span class="hljs-comment"> * assignment and consumer group coordination will be disabled.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;&lt;a name=&quot;failuredetection&quot;&gt;Detecting Consumer Failures&lt;/a&gt;&lt;/h3&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * After subscribing to a set of topics, the consumer will automatically join the group when &#123;@link #poll(Duration)&#125; is</span><br><span class="hljs-comment"> * invoked. The poll API is designed to ensure consumer liveness. As long as you continue to call poll, the consumer</span><br><span class="hljs-comment"> * will stay in the group and continue to receive messages from the partitions it was assigned. Underneath the covers,</span><br><span class="hljs-comment"> * the consumer sends periodic heartbeats to the server. If the consumer crashes or is unable to send heartbeats for</span><br><span class="hljs-comment"> * a duration of &#123;@code session.timeout.ms&#125;, then the consumer will be considered dead and its partitions will</span><br><span class="hljs-comment"> * be reassigned.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * It is also possible that the consumer could encounter a &quot;livelock&quot; situation where it is continuing</span><br><span class="hljs-comment"> * to send heartbeats, but no progress is being made. To prevent the consumer from holding onto its partitions</span><br><span class="hljs-comment"> * indefinitely in this case, we provide a liveness detection mechanism using the &#123;@code max.poll.interval.ms&#125;</span><br><span class="hljs-comment"> * setting. Basically if you don&#x27;t call poll at least as frequently as the configured max interval,</span><br><span class="hljs-comment"> * then the client will proactively leave the group so that another consumer can take over its partitions. When this happens,</span><br><span class="hljs-comment"> * you may see an offset commit failure (as indicated by a &#123;@link CommitFailedException&#125; thrown from a call to &#123;@link #commitSync()&#125;).</span><br><span class="hljs-comment"> * This is a safety mechanism which guarantees that only active members of the group are able to commit offsets.</span><br><span class="hljs-comment"> * So to stay in the group, you must continue to call poll.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The consumer provides two configuration settings to control the behavior of the poll loop:</span><br><span class="hljs-comment"> * &lt;ol&gt;</span><br><span class="hljs-comment"> *     &lt;li&gt;&lt;code&gt;max.poll.interval.ms&lt;/code&gt;: By increasing the interval between expected polls, you can give</span><br><span class="hljs-comment"> *     the consumer more time to handle a batch of records returned from &#123;@link #poll(Duration)&#125;. The drawback</span><br><span class="hljs-comment"> *     is that increasing this value may delay a group rebalance since the consumer will only join the rebalance</span><br><span class="hljs-comment"> *     inside the call to poll. You can use this setting to bound the time to finish a rebalance, but</span><br><span class="hljs-comment"> *     you risk slower progress if the consumer cannot actually call &#123;@link #poll(Duration) poll&#125; often enough.&lt;/li&gt;</span><br><span class="hljs-comment"> *     &lt;li&gt;&lt;code&gt;max.poll.records&lt;/code&gt;: Use this setting to limit the total records returned from a single</span><br><span class="hljs-comment"> *     call to poll. This can make it easier to predict the maximum that must be handled within each poll</span><br><span class="hljs-comment"> *     interval. By tuning this value, you may be able to reduce the poll interval, which will reduce the</span><br><span class="hljs-comment"> *     impact of group rebalancing.&lt;/li&gt;</span><br><span class="hljs-comment"> * &lt;/ol&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * For use cases where message processing time varies unpredictably, neither of these options may be sufficient.</span><br><span class="hljs-comment"> * The recommended way to handle these cases is to move message processing to another thread, which allows</span><br><span class="hljs-comment"> * the consumer to continue calling &#123;@link #poll(Duration) poll&#125; while the processor is still working.</span><br><span class="hljs-comment"> * Some care must be taken to ensure that committed offsets do not get ahead of the actual position.</span><br><span class="hljs-comment"> * Typically, you must disable automatic commits and manually commit processed offsets for records only after the</span><br><span class="hljs-comment"> * thread has finished handling them (depending on the delivery semantics you need).</span><br><span class="hljs-comment"> * Note also that you will need to &#123;@link #pause(Collection) pause&#125; the partition so that no new records are received</span><br><span class="hljs-comment"> * from poll until after thread has finished handling those previously returned.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;Usage Examples&lt;/h3&gt;</span><br><span class="hljs-comment"> * The consumer APIs offer flexibility to cover a variety of consumption use cases. Here are some examples to</span><br><span class="hljs-comment"> * demonstrate how to use them.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;Automatic Offset Committing&lt;/h4&gt;</span><br><span class="hljs-comment"> * This example demonstrates a simple usage of Kafka&#x27;s consumer api that relies on automatic offset committing.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> *     Properties props = new Properties();</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;bootstrap.servers&amp;quot;, &amp;quot;localhost:9092&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;group.id&amp;quot;, &amp;quot;test&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;enable.auto.commit&amp;quot;, &amp;quot;true&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;auto.commit.interval.ms&amp;quot;, &amp;quot;1000&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;key.deserializer&amp;quot;, &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;value.deserializer&amp;quot;, &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;);</span><br><span class="hljs-comment"> *     KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props);</span><br><span class="hljs-comment"> *     consumer.subscribe(Arrays.asList(&amp;quot;foo&amp;quot;, &amp;quot;bar&amp;quot;));</span><br><span class="hljs-comment"> *     while (true) &#123;</span><br><span class="hljs-comment"> *         ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(100));</span><br><span class="hljs-comment"> *         for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records)</span><br><span class="hljs-comment"> *             System.out.printf(&amp;quot;offset = %d, key = %s, value = %s%n&amp;quot;, record.offset(), record.key(), record.value());</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The connection to the cluster is bootstrapped by specifying a list of one or more brokers to contact using the</span><br><span class="hljs-comment"> * configuration &#123;@code bootstrap.servers&#125;. This list is just used to discover the rest of the brokers in the</span><br><span class="hljs-comment"> * cluster and need not be an exhaustive list of servers in the cluster (though you may want to specify more than one in</span><br><span class="hljs-comment"> * case there are servers down when the client is connecting).</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Setting &#123;@code enable.auto.commit&#125; means that offsets are committed automatically with a frequency controlled by</span><br><span class="hljs-comment"> * the config &#123;@code auto.commit.interval.ms&#125;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * In this example the consumer is subscribing to the topics &lt;i&gt;foo&lt;/i&gt; and &lt;i&gt;bar&lt;/i&gt; as part of a group of consumers</span><br><span class="hljs-comment"> * called &lt;i&gt;test&lt;/i&gt; as configured with &#123;@code group.id&#125;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The deserializer settings specify how to turn bytes into objects. For example, by specifying string deserializers, we</span><br><span class="hljs-comment"> * are saying that our record&#x27;s key and value will just be simple strings.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;Manual Offset Control&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Instead of relying on the consumer to periodically commit consumed offsets, users can also control when records</span><br><span class="hljs-comment"> * should be considered as consumed and hence commit their offsets. This is useful when the consumption of the messages</span><br><span class="hljs-comment"> * is coupled with some processing logic and hence a message should not be considered as consumed until it is completed processing.</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> *     Properties props = new Properties();</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;bootstrap.servers&amp;quot;, &amp;quot;localhost:9092&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;group.id&amp;quot;, &amp;quot;test&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;enable.auto.commit&amp;quot;, &amp;quot;false&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;key.deserializer&amp;quot;, &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;);</span><br><span class="hljs-comment"> *     props.setProperty(&amp;quot;value.deserializer&amp;quot;, &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;);</span><br><span class="hljs-comment"> *     KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props);</span><br><span class="hljs-comment"> *     consumer.subscribe(Arrays.asList(&amp;quot;foo&amp;quot;, &amp;quot;bar&amp;quot;));</span><br><span class="hljs-comment"> *     final int minBatchSize = 200;</span><br><span class="hljs-comment"> *     List&amp;lt;ConsumerRecord&amp;lt;String, String&amp;gt;&amp;gt; buffer = new ArrayList&amp;lt;&amp;gt;();</span><br><span class="hljs-comment"> *     while (true) &#123;</span><br><span class="hljs-comment"> *         ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(100));</span><br><span class="hljs-comment"> *         for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records) &#123;</span><br><span class="hljs-comment"> *             buffer.add(record);</span><br><span class="hljs-comment"> *         &#125;</span><br><span class="hljs-comment"> *         if (buffer.size() &amp;gt;= minBatchSize) &#123;</span><br><span class="hljs-comment"> *             insertIntoDb(buffer);</span><br><span class="hljs-comment"> *             consumer.commitSync();</span><br><span class="hljs-comment"> *             buffer.clear();</span><br><span class="hljs-comment"> *         &#125;</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * In this example we will consume a batch of records and batch them up in memory. When we have enough records</span><br><span class="hljs-comment"> * batched, we will insert them into a database. If we allowed offsets to auto commit as in the previous example, records</span><br><span class="hljs-comment"> * would be considered consumed after they were returned to the user in &#123;@link #poll(Duration) poll&#125;. It would then be</span><br><span class="hljs-comment"> * possible</span><br><span class="hljs-comment"> * for our process to fail after batching the records, but before they had been inserted into the database.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * To avoid this, we will manually commit the offsets only after the corresponding records have been inserted into the</span><br><span class="hljs-comment"> * database. This gives us exact control of when a record is considered consumed. This raises the opposite possibility:</span><br><span class="hljs-comment"> * the process could fail in the interval after the insert into the database but before the commit (even though this</span><br><span class="hljs-comment"> * would likely just be a few milliseconds, it is a possibility). In this case the process that took over consumption</span><br><span class="hljs-comment"> * would consume from last committed offset and would repeat the insert of the last batch of data. Used in this way</span><br><span class="hljs-comment"> * Kafka provides what is often called &quot;at-least-once&quot; delivery guarantees, as each record will likely be delivered one</span><br><span class="hljs-comment"> * time but in failure cases could be duplicated.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;b&gt;Note: Using automatic offset commits can also give you &quot;at-least-once&quot; delivery, but the requirement is that</span><br><span class="hljs-comment"> * you must consume all data returned from each call to &#123;@link #poll(Duration)&#125; before any subsequent calls, or before</span><br><span class="hljs-comment"> * &#123;@link #close() closing&#125; the consumer. If you fail to do either of these, it is possible for the committed offset</span><br><span class="hljs-comment"> * to get ahead of the consumed position, which results in missing records. The advantage of using manual offset</span><br><span class="hljs-comment"> * control is that you have direct control over when a record is considered &quot;consumed.&quot;&lt;/b&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The above example uses &#123;@link #commitSync() commitSync&#125; to mark all received records as committed. In some cases</span><br><span class="hljs-comment"> * you may wish to have even finer control over which records have been committed by specifying an offset explicitly.</span><br><span class="hljs-comment"> * In the example below we commit offset after we finish handling the records in each partition.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> *     try &#123;</span><br><span class="hljs-comment"> *         while(running) &#123;</span><br><span class="hljs-comment"> *             ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(Long.MAX_VALUE));</span><br><span class="hljs-comment"> *             for (TopicPartition partition : records.partitions()) &#123;</span><br><span class="hljs-comment"> *                 List&amp;lt;ConsumerRecord&amp;lt;String, String&amp;gt;&amp;gt; partitionRecords = records.records(partition);</span><br><span class="hljs-comment"> *                 for (ConsumerRecord&amp;lt;String, String&amp;gt; record : partitionRecords) &#123;</span><br><span class="hljs-comment"> *                     System.out.println(record.offset() + &amp;quot;: &amp;quot; + record.value());</span><br><span class="hljs-comment"> *                 &#125;</span><br><span class="hljs-comment"> *                 long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset();</span><br><span class="hljs-comment"> *                 consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1)));</span><br><span class="hljs-comment"> *             &#125;</span><br><span class="hljs-comment"> *         &#125;</span><br><span class="hljs-comment"> *     &#125; finally &#123;</span><br><span class="hljs-comment"> *       consumer.close();</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;b&gt;Note: The committed offset should always be the offset of the next message that your application will read.&lt;/b&gt;</span><br><span class="hljs-comment"> * Thus, when calling &#123;@link #commitSync(Map) commitSync(offsets)&#125; you should add one to the offset of the last message processed.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;&lt;a name=&quot;manualassignment&quot;&gt;Manual Partition Assignment&lt;/a&gt;&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * In the previous examples, we subscribed to the topics we were interested in and let Kafka dynamically assign a</span><br><span class="hljs-comment"> * fair share of the partitions for those topics based on the active consumers in the group. However, in</span><br><span class="hljs-comment"> * some cases you may need finer control over the specific partitions that are assigned. For example:</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;If the process is maintaining some kind of local state associated with that partition (like a</span><br><span class="hljs-comment"> * local on-disk key-value store), then it should only get records for the partition it is maintaining on disk.</span><br><span class="hljs-comment"> * &lt;li&gt;If the process itself is highly available and will be restarted if it fails (perhaps using a</span><br><span class="hljs-comment"> * cluster management framework like YARN, Mesos, or AWS facilities, or as part of a stream processing framework). In</span><br><span class="hljs-comment"> * this case there is no need for Kafka to detect the failure and reassign the partition since the consuming process</span><br><span class="hljs-comment"> * will be restarted on another machine.</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * To use this mode, instead of subscribing to the topic using &#123;@link #subscribe(Collection) subscribe&#125;, you just call</span><br><span class="hljs-comment"> * &#123;@link #assign(Collection)&#125; with the full list of partitions that you want to consume.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> *     String topic = &amp;quot;foo&amp;quot;;</span><br><span class="hljs-comment"> *     TopicPartition partition0 = new TopicPartition(topic, 0);</span><br><span class="hljs-comment"> *     TopicPartition partition1 = new TopicPartition(topic, 1);</span><br><span class="hljs-comment"> *     consumer.assign(Arrays.asList(partition0, partition1));</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Once assigned, you can call &#123;@link #poll(Duration) poll&#125; in a loop, just as in the preceding examples to consume</span><br><span class="hljs-comment"> * records. The group that the consumer specifies is still used for committing offsets, but now the set of partitions</span><br><span class="hljs-comment"> * will only change with another call to &#123;@link #assign(Collection) assign&#125;. Manual partition assignment does</span><br><span class="hljs-comment"> * not use group coordination, so consumer failures will not cause assigned partitions to be rebalanced. Each consumer</span><br><span class="hljs-comment"> * acts independently even if it shares a groupId with another consumer. To avoid offset commit conflicts, you should</span><br><span class="hljs-comment"> * usually ensure that the groupId is unique for each consumer instance.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Note that it isn&#x27;t possible to mix manual partition assignment (i.e. using &#123;@link #assign(Collection) assign&#125;)</span><br><span class="hljs-comment"> * with dynamic partition assignment through topic subscription (i.e. using &#123;@link #subscribe(Collection) subscribe&#125;).</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;&lt;a name=&quot;rebalancecallback&quot;&gt;Storing Offsets Outside Kafka&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The consumer application need not use Kafka&#x27;s built-in offset storage, it can store offsets in a store of its own</span><br><span class="hljs-comment"> * choosing. The primary use case for this is allowing the application to store both the offset and the results of the</span><br><span class="hljs-comment"> * consumption in the same system in a way that both the results and offsets are stored atomically. This is not always</span><br><span class="hljs-comment"> * possible, but when it is it will make the consumption fully atomic and give &quot;exactly once&quot; semantics that are</span><br><span class="hljs-comment"> * stronger than the default &quot;at-least once&quot; semantics you get with Kafka&#x27;s offset commit functionality.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Here are a couple of examples of this type of usage:</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;If the results of the consumption are being stored in a relational database, storing the offset in the database</span><br><span class="hljs-comment"> * as well can allow committing both the results and offset in a single transaction. Thus either the transaction will</span><br><span class="hljs-comment"> * succeed and the offset will be updated based on what was consumed or the result will not be stored and the offset</span><br><span class="hljs-comment"> * won&#x27;t be updated.</span><br><span class="hljs-comment"> * &lt;li&gt;If the results are being stored in a local store it may be possible to store the offset there as well. For</span><br><span class="hljs-comment"> * example a search index could be built by subscribing to a particular partition and storing both the offset and the</span><br><span class="hljs-comment"> * indexed data together. If this is done in a way that is atomic, it is often possible to have it be the case that even</span><br><span class="hljs-comment"> * if a crash occurs that causes unsync&#x27;d data to be lost, whatever is left has the corresponding offset stored as well.</span><br><span class="hljs-comment"> * This means that in this case the indexing process that comes back having lost recent updates just resumes indexing</span><br><span class="hljs-comment"> * from what it has ensuring that no updates are lost.</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Each record comes with its own offset, so to manage your own offset you just need to do the following:</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;Configure &lt;code&gt;enable.auto.commit=false&lt;/code&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;Use the offset provided with each &#123;@link ConsumerRecord&#125; to save your position.</span><br><span class="hljs-comment"> * &lt;li&gt;On restart restore the position of the consumer using &#123;@link #seek(TopicPartition, long)&#125;.</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * This type of usage is simplest when the partition assignment is also done manually (this would be likely in the</span><br><span class="hljs-comment"> * search index use case described above). If the partition assignment is done automatically special care is</span><br><span class="hljs-comment"> * needed to handle the case where partition assignments change. This can be done by providing a</span><br><span class="hljs-comment"> * &#123;@link ConsumerRebalanceListener&#125; instance in the call to &#123;@link #subscribe(Collection, ConsumerRebalanceListener)&#125;</span><br><span class="hljs-comment"> * and &#123;@link #subscribe(Pattern, ConsumerRebalanceListener)&#125;.</span><br><span class="hljs-comment"> * For example, when partitions are taken from a consumer the consumer will want to commit its offset for those partitions by</span><br><span class="hljs-comment"> * implementing &#123;@link ConsumerRebalanceListener#onPartitionsRevoked(Collection)&#125;. When partitions are assigned to a</span><br><span class="hljs-comment"> * consumer, the consumer will want to look up the offset for those new partitions and correctly initialize the consumer</span><br><span class="hljs-comment"> * to that position by implementing &#123;@link ConsumerRebalanceListener#onPartitionsAssigned(Collection)&#125;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Another common use for &#123;@link ConsumerRebalanceListener&#125; is to flush any caches the application maintains for</span><br><span class="hljs-comment"> * partitions that are moved elsewhere.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;Controlling The Consumer&#x27;s Position&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * In most use cases the consumer will simply consume records from beginning to end, periodically committing its</span><br><span class="hljs-comment"> * position (either automatically or manually). However Kafka allows the consumer to manually control its position,</span><br><span class="hljs-comment"> * moving forward or backwards in a partition at will. This means a consumer can re-consume older records, or skip to</span><br><span class="hljs-comment"> * the most recent records without actually consuming the intermediate records.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * There are several instances where manually controlling the consumer&#x27;s position can be useful.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * One case is for time-sensitive record processing it may make sense for a consumer that falls far enough behind to not</span><br><span class="hljs-comment"> * attempt to catch up processing all records, but rather just skip to the most recent records.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Another use case is for a system that maintains local state as described in the previous section. In such a system</span><br><span class="hljs-comment"> * the consumer will want to initialize its position on start-up to whatever is contained in the local store. Likewise</span><br><span class="hljs-comment"> * if the local state is destroyed (say because the disk is lost) the state may be recreated on a new machine by</span><br><span class="hljs-comment"> * re-consuming all the data and recreating the state (assuming that Kafka is retaining sufficient history).</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Kafka allows specifying the position using &#123;@link #seek(TopicPartition, long)&#125; to specify the new position. Special</span><br><span class="hljs-comment"> * methods for seeking to the earliest and latest offset the server maintains are also available (</span><br><span class="hljs-comment"> * &#123;@link #seekToBeginning(Collection)&#125; and &#123;@link #seekToEnd(Collection)&#125; respectively).</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;Consumption Flow Control&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * If a consumer is assigned multiple partitions to fetch data from, it will try to consume from all of them at the same time,</span><br><span class="hljs-comment"> * effectively giving these partitions the same priority for consumption. However in some cases consumers may want to</span><br><span class="hljs-comment"> * first focus on fetching from some subset of the assigned partitions at full speed, and only start fetching other partitions</span><br><span class="hljs-comment"> * when these partitions have few or no data to consume.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * One of such cases is stream processing, where processor fetches from two topics and performs the join on these two streams.</span><br><span class="hljs-comment"> * When one of the topics is long lagging behind the other, the processor would like to pause fetching from the ahead topic</span><br><span class="hljs-comment"> * in order to get the lagging stream to catch up. Another example is bootstraping upon consumer starting up where there are</span><br><span class="hljs-comment"> * a lot of history data to catch up, the applications usually want to get the latest data on some of the topics before consider</span><br><span class="hljs-comment"> * fetching other topics.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Kafka supports dynamic controlling of consumption flows by using &#123;@link #pause(Collection)&#125; and &#123;@link #resume(Collection)&#125;</span><br><span class="hljs-comment"> * to pause the consumption on the specified assigned partitions and resume the consumption</span><br><span class="hljs-comment"> * on the specified paused partitions respectively in the future &#123;@link #poll(Duration)&#125; calls.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;Reading Transactional Messages&lt;/h3&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Transactions were introduced in Kafka 0.11.0 wherein applications can write to multiple topics and partitions atomically.</span><br><span class="hljs-comment"> * In order for this to work, consumers reading from these partitions should be configured to only read committed data.</span><br><span class="hljs-comment"> * This can be achieved by setting the &#123;@code isolation.level=read_committed&#125; in the consumer&#x27;s configuration.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * In &lt;code&gt;read_committed&lt;/code&gt; mode, the consumer will read only those transactional messages which have been</span><br><span class="hljs-comment"> * successfully committed. It will continue to read non-transactional messages as before. There is no client-side</span><br><span class="hljs-comment"> * buffering in &lt;code&gt;read_committed&lt;/code&gt; mode. Instead, the end offset of a partition for a &lt;code&gt;read_committed&lt;/code&gt;</span><br><span class="hljs-comment"> * consumer would be the offset of the first message in the partition belonging to an open transaction. This offset</span><br><span class="hljs-comment"> * is known as the &#x27;Last Stable Offset&#x27;(LSO).&lt;/p&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * A &#123;@code read_committed&#125; consumer will only read up to the LSO and filter out any transactional</span><br><span class="hljs-comment"> * messages which have been aborted. The LSO also affects the behavior of &#123;@link #seekToEnd(Collection)&#125; and</span><br><span class="hljs-comment"> * &#123;@link #endOffsets(Collection)&#125; for &#123;@code read_committed&#125; consumers, details of which are in each method&#x27;s documentation.</span><br><span class="hljs-comment"> * Finally, the fetch lag metrics are also adjusted to be relative to the LSO for &#123;@code read_committed&#125; consumers.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Partitions with transactional messages will include commit or abort markers which indicate the result of a transaction.</span><br><span class="hljs-comment"> * There markers are not returned to applications, yet have an offset in the log. As a result, applications reading from</span><br><span class="hljs-comment"> * topics with transactional messages will see gaps in the consumed offsets. These missing messages would be the transaction</span><br><span class="hljs-comment"> * markers, and they are filtered out for consumers in both isolation levels. Additionally, applications using</span><br><span class="hljs-comment"> * &#123;@code read_committed&#125; consumers may also see gaps due to aborted transactions, since those messages would not</span><br><span class="hljs-comment"> * be returned by the consumer and yet would have valid offsets.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h3&gt;&lt;a name=&quot;multithreaded&quot;&gt;Multi-threaded Processing&lt;/a&gt;&lt;/h3&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The Kafka consumer is NOT thread-safe. All network I/O happens in the thread of the application</span><br><span class="hljs-comment"> * making the call. It is the responsibility of the user to ensure that multi-threaded access</span><br><span class="hljs-comment"> * is properly synchronized. Un-synchronized access will result in &#123;@link ConcurrentModificationException&#125;.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The only exception to this rule is &#123;@link #wakeup()&#125;, which can safely be used from an external thread to</span><br><span class="hljs-comment"> * interrupt an active operation. In this case, a &#123;@link org.apache.kafka.common.errors.WakeupException&#125; will be</span><br><span class="hljs-comment"> * thrown from the thread blocking on the operation. This can be used to shutdown the consumer from another thread.</span><br><span class="hljs-comment"> * The following snippet shows the typical pattern:</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> * public class KafkaConsumerRunner implements Runnable &#123;</span><br><span class="hljs-comment"> *     private final AtomicBoolean closed = new AtomicBoolean(false);</span><br><span class="hljs-comment"> *     private final KafkaConsumer consumer;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> *     public KafkaConsumerRunner(KafkaConsumer consumer) &#123;</span><br><span class="hljs-comment"> *       this.consumer = consumer;</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> *     &#123;@literal&#125;@Override</span><br><span class="hljs-comment"> *     public void run() &#123;</span><br><span class="hljs-comment"> *         try &#123;</span><br><span class="hljs-comment"> *             consumer.subscribe(Arrays.asList(&quot;topic&quot;));</span><br><span class="hljs-comment"> *             while (!closed.get()) &#123;</span><br><span class="hljs-comment"> *                 ConsumerRecords records = consumer.poll(Duration.ofMillis(10000));</span><br><span class="hljs-comment"> *                 // Handle new records</span><br><span class="hljs-comment"> *             &#125;</span><br><span class="hljs-comment"> *         &#125; catch (WakeupException e) &#123;</span><br><span class="hljs-comment"> *             // Ignore exception if closing</span><br><span class="hljs-comment"> *             if (!closed.get()) throw e;</span><br><span class="hljs-comment"> *         &#125; finally &#123;</span><br><span class="hljs-comment"> *             consumer.close();</span><br><span class="hljs-comment"> *         &#125;</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> *     // Shutdown hook which can be called from a separate thread</span><br><span class="hljs-comment"> *     public void shutdown() &#123;</span><br><span class="hljs-comment"> *         closed.set(true);</span><br><span class="hljs-comment"> *         consumer.wakeup();</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Then in a separate thread, the consumer can be shutdown by setting the closed flag and waking up the consumer.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> *     closed.set(true);</span><br><span class="hljs-comment"> *     consumer.wakeup();</span><br><span class="hljs-comment"> * &lt;/pre&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Note that while it is possible to use thread interrupts instead of &#123;@link #wakeup()&#125; to abort a blocking operation</span><br><span class="hljs-comment"> * (in which case, &#123;@link InterruptException&#125; will be raised), we discourage their use since they may cause a clean</span><br><span class="hljs-comment"> * shutdown of the consumer to be aborted. Interrupts are mainly supported for those cases where using &#123;@link #wakeup()&#125;</span><br><span class="hljs-comment"> * is impossible, e.g. when a consumer thread is managed by code that is unaware of the Kafka client.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * We have intentionally avoided implementing a particular threading model for processing. This leaves several</span><br><span class="hljs-comment"> * options for implementing multi-threaded processing of records.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;1. One Consumer Per Thread&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * A simple option is to give each thread its own consumer instance. Here are the pros and cons of this approach:</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;PRO&lt;/b&gt;: It is the easiest to implement</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;PRO&lt;/b&gt;: It is often the fastest as no inter-thread co-ordination is needed</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;PRO&lt;/b&gt;: It makes in-order processing on a per-partition basis very easy to implement (each thread just</span><br><span class="hljs-comment"> * processes messages in the order it receives them).</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;CON&lt;/b&gt;: More consumers means more TCP connections to the cluster (one per thread). In general Kafka handles</span><br><span class="hljs-comment"> * connections very efficiently so this is generally a small cost.</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;CON&lt;/b&gt;: Multiple consumers means more requests being sent to the server and slightly less batching of data</span><br><span class="hljs-comment"> * which can cause some drop in I/O throughput.</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;CON&lt;/b&gt;: The number of total threads across all processes will be limited by the total number of partitions.</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;h4&gt;2. Decouple Consumption and Processing&lt;/h4&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Another alternative is to have one or more consumer threads that do all data consumption and hands off</span><br><span class="hljs-comment"> * &#123;@link ConsumerRecords&#125; instances to a blocking queue consumed by a pool of processor threads that actually handle</span><br><span class="hljs-comment"> * the record processing.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This option likewise has pros and cons:</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;PRO&lt;/b&gt;: This option allows independently scaling the number of consumers and processors. This makes it</span><br><span class="hljs-comment"> * possible to have a single consumer that feeds many processor threads, avoiding any limitation on partitions.</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;CON&lt;/b&gt;: Guaranteeing order across the processors requires particular care as the threads will execute</span><br><span class="hljs-comment"> * independently an earlier chunk of data may actually be processed after a later chunk of data just due to the luck of</span><br><span class="hljs-comment"> * thread execution timing. For processing that has no ordering requirements this is not a problem.</span><br><span class="hljs-comment"> * &lt;li&gt;&lt;b&gt;CON&lt;/b&gt;: Manually committing the position becomes harder as it requires that all threads co-ordinate to ensure</span><br><span class="hljs-comment"> * that processing is complete for that partition.</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * There are many possible variations on this approach. For example each processor thread can have its own queue, and</span><br><span class="hljs-comment"> * the consumer threads can hash into these queues using the TopicPartition to ensure in-order consumption and simplify</span><br><span class="hljs-comment"> * commit.</span><br><span class="hljs-comment"> */</span><br>public <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaConsumer&lt;K</span>, <span class="hljs-title">V&gt;</span> <span class="hljs-title">implements</span> <span class="hljs-title">Consumer&lt;K</span>, <span class="hljs-title">V&gt;</span> </span>&#123;<br>  <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a><a target="_blank" rel="noopener" href="https://sourcegraph.com/github.com/apache/kafka@3.3/-/blob/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java?L93">Producer</a></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * A Kafka client that publishes records to the Kafka cluster.</span><br><span class="hljs-comment"> * &lt;P&gt;</span><br><span class="hljs-comment"> * The producer is &lt;i&gt;thread safe&lt;/i&gt; and sharing a single producer instance across threads will generally be faster than</span><br><span class="hljs-comment"> * having multiple instances.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * Here is a simple example of using the producer to send records with strings containing sequential numbers as the key/value</span><br><span class="hljs-comment"> * pairs.</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> * &#123;@code</span><br><span class="hljs-comment"> * Properties props = new Properties();</span><br><span class="hljs-comment"> * props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="hljs-comment"> * props.put(&quot;linger.ms&quot;, 1);</span><br><span class="hljs-comment"> * props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="hljs-comment"> * props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="hljs-comment"> * for (int i = 0; i &lt; 100; i++)</span><br><span class="hljs-comment"> *     producer.send(new ProducerRecord&lt;String, String&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * producer.close();</span><br><span class="hljs-comment"> * &#125;&lt;/pre&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The producer consists of a pool of buffer space that holds records that haven&#x27;t yet been transmitted to the server</span><br><span class="hljs-comment"> * as well as a background I/O thread that is responsible for turning these records into requests and transmitting them</span><br><span class="hljs-comment"> * to the cluster. Failure to close the producer after use will leak these resources.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &#123;@link #send(ProducerRecord) send()&#125; method is asynchronous. When called, it adds the record to a buffer of pending record sends</span><br><span class="hljs-comment"> * and immediately returns. This allows the producer to batch together individual records for efficiency.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &lt;code&gt;acks&lt;/code&gt; config controls the criteria under which requests are considered complete. The default setting &quot;all&quot;</span><br><span class="hljs-comment"> * will result in blocking on the full commit of the record, the slowest but most durable setting.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * If the request fails, the producer can automatically retry. The &lt;code&gt;retries&lt;/code&gt; setting defaults to &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt;, and</span><br><span class="hljs-comment"> * it&#x27;s recommended to use &lt;code&gt;delivery.timeout.ms&lt;/code&gt; to control retry behavior, instead of &lt;code&gt;retries&lt;/code&gt;.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The producer maintains buffers of unsent records for each partition. These buffers are of a size specified by</span><br><span class="hljs-comment"> * the &lt;code&gt;batch.size&lt;/code&gt; config. Making this larger can result in more batching, but requires more memory (since we will</span><br><span class="hljs-comment"> * generally have one of these buffers for each active partition).</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * By default a buffer is available to send immediately even if there is additional unused space in the buffer. However if you</span><br><span class="hljs-comment"> * want to reduce the number of requests you can set &lt;code&gt;linger.ms&lt;/code&gt; to something greater than 0. This will</span><br><span class="hljs-comment"> * instruct the producer to wait up to that number of milliseconds before sending a request in hope that more records will</span><br><span class="hljs-comment"> * arrive to fill up the same batch. This is analogous to Nagle&#x27;s algorithm in TCP. For example, in the code snippet above,</span><br><span class="hljs-comment"> * likely all 100 records would be sent in a single request since we set our linger time to 1 millisecond. However this setting</span><br><span class="hljs-comment"> * would add 1 millisecond of latency to our request waiting for more records to arrive if we didn&#x27;t fill up the buffer. Note that</span><br><span class="hljs-comment"> * records that arrive close together in time will generally batch together even with &lt;code&gt;linger.ms=0&lt;/code&gt;. So, under heavy load,</span><br><span class="hljs-comment"> * batching will occur regardless of the linger configuration; however setting this to something larger than 0 can lead to fewer, more</span><br><span class="hljs-comment"> * efficient requests when not under maximal load at the cost of a small amount of latency.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &lt;code&gt;buffer.memory&lt;/code&gt; controls the total amount of memory available to the producer for buffering. If records</span><br><span class="hljs-comment"> * are sent faster than they can be transmitted to the server then this buffer space will be exhausted. When the buffer space is</span><br><span class="hljs-comment"> * exhausted additional send calls will block. The threshold for time to block is determined by &lt;code&gt;max.block.ms&lt;/code&gt; after which it throws</span><br><span class="hljs-comment"> * a TimeoutException.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The &lt;code&gt;key.serializer&lt;/code&gt; and &lt;code&gt;value.serializer&lt;/code&gt; instruct how to turn the key and value objects the user provides with</span><br><span class="hljs-comment"> * their &lt;code&gt;ProducerRecord&lt;/code&gt; into bytes. You can use the included &#123;@link org.apache.kafka.common.serialization.ByteArraySerializer&#125; or</span><br><span class="hljs-comment"> * &#123;@link org.apache.kafka.common.serialization.StringSerializer&#125; for simple string or byte types.</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * From Kafka 0.11, the KafkaProducer supports two additional modes: the idempotent producer and the transactional producer.</span><br><span class="hljs-comment"> * The idempotent producer strengthens Kafka&#x27;s delivery semantics from at least once to exactly once delivery. In particular</span><br><span class="hljs-comment"> * producer retries will no longer introduce duplicates. The transactional producer allows an application to send messages</span><br><span class="hljs-comment"> * to multiple partitions (and topics!) atomically.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * From Kafka 3.0, the &lt;code&gt;enable.idempotence&lt;/code&gt; configuration defaults to true. When enabling idempotence,</span><br><span class="hljs-comment"> * &lt;code&gt;retries&lt;/code&gt; config will default to &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt; and the &lt;code&gt;acks&lt;/code&gt; config will</span><br><span class="hljs-comment"> * default to &lt;code&gt;all&lt;/code&gt;. There are no API changes for the idempotent producer, so existing applications will</span><br><span class="hljs-comment"> * not need to be modified to take advantage of this feature.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * To take advantage of the idempotent producer, it is imperative to avoid application level re-sends since these cannot</span><br><span class="hljs-comment"> * be de-duplicated. As such, if an application enables idempotence, it is recommended to leave the &lt;code&gt;retries&lt;/code&gt;</span><br><span class="hljs-comment"> * config unset, as it will be defaulted to &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt;. Additionally, if a &#123;@link #send(ProducerRecord)&#125;</span><br><span class="hljs-comment"> * returns an error even with infinite retries (for instance if the message expires in the buffer before being sent),</span><br><span class="hljs-comment"> * then it is recommended to shut down the producer and check the contents of the last produced message to ensure that</span><br><span class="hljs-comment"> * it is not duplicated. Finally, the producer can only guarantee idempotence for messages sent within a single session.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;To use the transactional producer and the attendant APIs, you must set the &lt;code&gt;transactional.id&lt;/code&gt;</span><br><span class="hljs-comment"> * configuration property. If the &lt;code&gt;transactional.id&lt;/code&gt; is set, idempotence is automatically enabled along with</span><br><span class="hljs-comment"> * the producer configs which idempotence depends on. Further, topics which are included in transactions should be configured</span><br><span class="hljs-comment"> * for durability. In particular, the &lt;code&gt;replication.factor&lt;/code&gt; should be at least &lt;code&gt;3&lt;/code&gt;, and the</span><br><span class="hljs-comment"> * &lt;code&gt;min.insync.replicas&lt;/code&gt; for these topics should be set to 2. Finally, in order for transactional guarantees</span><br><span class="hljs-comment"> * to be realized from end-to-end, the consumers must be configured to read only committed messages as well.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The purpose of the &lt;code&gt;transactional.id&lt;/code&gt; is to enable transaction recovery across multiple sessions of a</span><br><span class="hljs-comment"> * single producer instance. It would typically be derived from the shard identifier in a partitioned, stateful, application.</span><br><span class="hljs-comment"> * As such, it should be unique to each producer instance running within a partitioned application.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;All the new transactional APIs are blocking and will throw exceptions on failure. The example</span><br><span class="hljs-comment"> * below illustrates how the new APIs are meant to be used. It is similar to the example above, except that all</span><br><span class="hljs-comment"> * 100 messages are part of a single transaction.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * &lt;pre&gt;</span><br><span class="hljs-comment"> * &#123;@code</span><br><span class="hljs-comment"> * Properties props = new Properties();</span><br><span class="hljs-comment"> * props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="hljs-comment"> * props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);</span><br><span class="hljs-comment"> * Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * producer.initTransactions();</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * try &#123;</span><br><span class="hljs-comment"> *     producer.beginTransaction();</span><br><span class="hljs-comment"> *     for (int i = 0; i &lt; 100; i++)</span><br><span class="hljs-comment"> *         producer.send(new ProducerRecord&lt;&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));</span><br><span class="hljs-comment"> *     producer.commitTransaction();</span><br><span class="hljs-comment"> * &#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123;</span><br><span class="hljs-comment"> *     // We can&#x27;t recover from these exceptions, so our only option is to close the producer and exit.</span><br><span class="hljs-comment"> *     producer.close();</span><br><span class="hljs-comment"> * &#125; catch (KafkaException e) &#123;</span><br><span class="hljs-comment"> *     // For all other exceptions, just abort the transaction and try again.</span><br><span class="hljs-comment"> *     producer.abortTransaction();</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> * producer.close();</span><br><span class="hljs-comment"> * &#125; &lt;/pre&gt;</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * As is hinted at in the example, there can be only one open transaction per producer. All messages sent between the</span><br><span class="hljs-comment"> * &#123;@link #beginTransaction()&#125; and &#123;@link #commitTransaction()&#125; calls will be part of a single transaction. When the</span><br><span class="hljs-comment"> * &lt;code&gt;transactional.id&lt;/code&gt; is specified, all messages sent by the producer must be part of a transaction.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * The transactional producer uses exceptions to communicate error states. In particular, it is not required</span><br><span class="hljs-comment"> * to specify callbacks for &lt;code&gt;producer.send()&lt;/code&gt; or to call &lt;code&gt;.get()&lt;/code&gt; on the returned Future: a</span><br><span class="hljs-comment"> * &lt;code&gt;KafkaException&lt;/code&gt; would be thrown if any of the</span><br><span class="hljs-comment"> * &lt;code&gt;producer.send()&lt;/code&gt; or transactional calls hit an irrecoverable error during a transaction. See the &#123;@link #send(ProducerRecord)&#125;</span><br><span class="hljs-comment"> * documentation for more details about detecting errors from a transactional send.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;/p&gt;By calling</span><br><span class="hljs-comment"> * &lt;code&gt;producer.abortTransaction()&lt;/code&gt; upon receiving a &lt;code&gt;KafkaException&lt;/code&gt; we can ensure that any</span><br><span class="hljs-comment"> * successful writes are marked as aborted, hence keeping the transactional guarantees.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;p&gt;</span><br><span class="hljs-comment"> * This client can communicate with brokers that are version 0.10.0 or newer. Older or newer brokers may not support</span><br><span class="hljs-comment"> * certain client features.  For instance, the transactional APIs need broker versions 0.11.0 or later. You will receive an</span><br><span class="hljs-comment"> * &lt;code&gt;UnsupportedVersionException&lt;/code&gt; when invoking an API that is not available in the running broker version.</span><br><span class="hljs-comment"> * &lt;/p&gt;</span><br><span class="hljs-comment"> */</span><br>public <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaProducer&lt;K</span>, <span class="hljs-title">V&gt;</span> <span class="hljs-title">implements</span> <span class="hljs-title">Producer&lt;K</span>, <span class="hljs-title">V&gt;</span> </span>&#123;<br>	<span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure>

<p>Reference: <a target="_blank" rel="noopener" href="https://colobu.com/2015/03/23/kafka-internals/">Kafka 内幕：源代码High level分析</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Kafka Reator 模型源代码分析</div>
      <div>http://smalnote.github.io/2022/09/25/Kafka Reator 模型源代码分析/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>smalnote</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年9月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/11/20/%E5%85%A8%E5%B9%B2%E5%B7%A5%E7%A8%8B%E5%B8%88%EF%BC%9A%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%85%A5%E5%9D%91%E5%89%8D%E7%AB%AF%E6%80%BB%E7%BB%93/" title="全干工程师：后端工程师入坑前端总结">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">全干工程师：后端工程师入坑前端总结</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
